# 容器编排实践 / Container Orchestration Practice


<!-- TOC START -->

- [容器编排实践 / Container Orchestration Practice](#容器编排实践-container-orchestration-practice)
  - [概述 / Overview](#概述-overview)
  - [1. Kubernetes编排实践 / Kubernetes Orchestration Practice](#1-kubernetes编排实践-kubernetes-orchestration-practice)
    - [1.1 集群架构设计 / Cluster Architecture Design](#11-集群架构设计-cluster-architecture-design)
      - [1.1.1 高可用集群架构 / High Availability Cluster Architecture](#111-高可用集群架构-high-availability-cluster-architecture)
- [高可用Kubernetes集群架构](#高可用kubernetes集群架构)
- [负载均衡器配置](#负载均衡器配置)
      - [1.1.2 多区域部署架构 / Multi-Region Deployment Architecture](#112-多区域部署架构-multi-region-deployment-architecture)
- [多区域部署配置](#多区域部署配置)
    - [1.2 应用部署实践 / Application Deployment Practice](#12-应用部署实践-application-deployment-practice)
      - [1.2.1 微服务部署策略 / Microservice Deployment Strategy](#121-微服务部署策略-microservice-deployment-strategy)
- [蓝绿部署配置](#蓝绿部署配置)
- [金丝雀部署配置](#金丝雀部署配置)
      - [1.2.2 配置管理实践 / Configuration Management Practice](#122-配置管理实践-configuration-management-practice)
- [应用配置管理](#应用配置管理)
- [敏感信息管理](#敏感信息管理)
    - [1.3 自动扩缩容实践 / Auto-Scaling Practice](#13-自动扩缩容实践-auto-scaling-practice)
      - [1.3.1 HPA配置 / Horizontal Pod Autoscaler Configuration](#131-hpa配置-horizontal-pod-autoscaler-configuration)
- [水平Pod自动扩缩容](#水平pod自动扩缩容)
- [基于自定义指标的扩缩容](#基于自定义指标的扩缩容)
      - [1.3.2 VPA配置 / Vertical Pod Autoscaler Configuration](#132-vpa配置-vertical-pod-autoscaler-configuration)
- [垂直Pod自动扩缩容](#垂直pod自动扩缩容)
    - [1.4 网络策略实践 / Network Policy Practice](#14-网络策略实践-network-policy-practice)
      - [1.4.1 网络隔离策略 / Network Isolation Policy](#141-网络隔离策略-network-isolation-policy)
- [网络策略配置](#网络策略配置)
      - [1.4.2 服务网格集成 / Service Mesh Integration](#142-服务网格集成-service-mesh-integration)
- [Istio VirtualService配置](#istio-virtualservice配置)
    - [1.5 监控与日志实践 / Monitoring and Logging Practice](#15-监控与日志实践-monitoring-and-logging-practice)
      - [1.5.1 Prometheus监控配置 / Prometheus Monitoring Configuration](#151-prometheus监控配置-prometheus-monitoring-configuration)
- [Prometheus ServiceMonitor配置](#prometheus-servicemonitor配置)
- [Prometheus告警规则](#prometheus告警规则)
      - [1.5.2 日志收集配置 / Log Collection Configuration](#152-日志收集配置-log-collection-configuration)
- [Fluentd DaemonSet配置](#fluentd-daemonset配置)
  - [2. Docker Swarm编排实践 / Docker Swarm Orchestration Practice](#2-docker-swarm编排实践-docker-swarm-orchestration-practice)
    - [2.1 集群管理 / Cluster Management](#21-集群管理-cluster-management)
      - [2.1.1 集群初始化 / Cluster Initialization](#211-集群初始化-cluster-initialization)
- [初始化Swarm集群](#初始化swarm集群)
- [获取加入令牌](#获取加入令牌)
- [管理节点加入](#管理节点加入)
- [工作节点加入](#工作节点加入)
      - [2.1.2 服务部署 / Service Deployment](#212-服务部署-service-deployment)
- [docker-compose.yml](#docker-composeyml)
    - [2.2 服务发现与负载均衡 / Service Discovery and Load Balancing](#22-服务发现与负载均衡-service-discovery-and-load-balancing)
      - [2.2.1 服务发现配置 / Service Discovery Configuration](#221-服务发现配置-service-discovery-configuration)
- [服务发现配置](#服务发现配置)
      - [2.2.2 负载均衡策略 / Load Balancing Strategy](#222-负载均衡策略-load-balancing-strategy)
- [VIP模式负载均衡](#vip模式负载均衡)
    - [2.3 滚动更新策略 / Rolling Update Strategy](#23-滚动更新策略-rolling-update-strategy)
      - [2.3.1 蓝绿部署 / Blue-Green Deployment](#231-蓝绿部署-blue-green-deployment)
- [蓝绿部署脚本](#蓝绿部署脚本)
- [部署绿色版本](#部署绿色版本)
- [等待服务健康](#等待服务健康)
- [检查服务状态](#检查服务状态)
      - [2.3.2 金丝雀部署 / Canary Deployment](#232-金丝雀部署-canary-deployment)
- [金丝雀部署](#金丝雀部署)
  - [3. Apache Mesos编排实践 / Apache Mesos Orchestration Practice](#3-apache-mesos编排实践-apache-mesos-orchestration-practice)
    - [3.1 集群架构 / Cluster Architecture](#31-集群架构-cluster-architecture)
      - [3.1.1 Mesos集群配置 / Mesos Cluster Configuration](#311-mesos集群配置-mesos-cluster-configuration)
- [Mesos主节点配置](#mesos主节点配置)
- [Mesos从节点配置](#mesos从节点配置)
      - [3.1.2 Marathon应用编排 / Marathon Application Orchestration](#312-marathon应用编排-marathon-application-orchestration)
    - [3.2 资源管理 / Resource Management](#32-资源管理-resource-management)
      - [3.2.1 资源分配策略 / Resource Allocation Strategy](#321-资源分配策略-resource-allocation-strategy)
      - [3.2.2 资源隔离 / Resource Isolation](#322-资源隔离-resource-isolation)
  - [4. 故障处理与恢复 / Fault Handling and Recovery](#4-故障处理与恢复-fault-handling-and-recovery)
    - [4.1 故障检测 / Fault Detection](#41-故障检测-fault-detection)
      - [4.1.1 健康检查配置 / Health Check Configuration](#411-健康检查配置-health-check-configuration)
- [Kubernetes健康检查](#kubernetes健康检查)
      - [4.1.2 故障检测算法 / Fault Detection Algorithm](#412-故障检测算法-fault-detection-algorithm)
    - [4.2 故障恢复策略 / Fault Recovery Strategy](#42-故障恢复策略-fault-recovery-strategy)
      - [4.2.1 自动恢复机制 / Automatic Recovery Mechanism](#421-自动恢复机制-automatic-recovery-mechanism)
- [重启策略配置](#重启策略配置)
      - [4.2.2 故障转移策略 / Failover Strategy](#422-故障转移策略-failover-strategy)
- [故障转移配置](#故障转移配置)
  - [5. 性能优化实践 / Performance Optimization Practice](#5-性能优化实践-performance-optimization-practice)
    - [5.1 资源优化 / Resource Optimization](#51-资源优化-resource-optimization)
      - [5.1.1 资源限制配置 / Resource Limits Configuration](#511-资源限制配置-resource-limits-configuration)
- [资源限制配置](#资源限制配置)
      - [5.1.2 资源监控与调优 / Resource Monitoring and Tuning](#512-资源监控与调优-resource-monitoring-and-tuning)
    - [5.2 网络优化 / Network Optimization](#52-网络优化-network-optimization)
      - [5.2.1 网络策略优化 / Network Policy Optimization](#521-网络策略优化-network-policy-optimization)
- [网络优化配置](#网络优化配置)
  - [6. 安全实践 / Security Practice](#6-安全实践-security-practice)
    - [6.1 容器安全 / Container Security](#61-容器安全-container-security)
      - [6.1.1 安全策略配置 / Security Policy Configuration](#611-安全策略配置-security-policy-configuration)
- [Pod安全策略](#pod安全策略)
      - [6.1.2 镜像安全扫描 / Image Security Scanning](#612-镜像安全扫描-image-security-scanning)
- [镜像安全扫描](#镜像安全扫描)
    - [6.2 网络安全 / Network Security](#62-网络安全-network-security)
      - [6.2.1 网络策略实施 / Network Policy Implementation](#621-网络策略实施-network-policy-implementation)
- [严格网络策略](#严格网络策略)
  - [7. 最佳实践总结 / Best Practices Summary](#7-最佳实践总结-best-practices-summary)
    - [7.1 部署最佳实践 / Deployment Best Practices](#71-部署最佳实践-deployment-best-practices)
    - [7.2 运维最佳实践 / Operations Best Practices](#72-运维最佳实践-operations-best-practices)
    - [7.3 团队协作最佳实践 / Team Collaboration Best Practices](#73-团队协作最佳实践-team-collaboration-best-practices)
  - [参考文献 / References](#参考文献-references)

<!-- TOC END -->

## 概述 / Overview

容器编排是微服务架构中的核心技术，负责自动化容器的部署、扩展、监控和管理。本章节将深入探讨主流容器编排平台的实践应用。

Container orchestration is a core technology in microservice architecture, responsible for automating container deployment, scaling, monitoring, and management. This chapter will explore practical applications of mainstream container orchestration platforms.

## 1. Kubernetes编排实践 / Kubernetes Orchestration Practice

### 1.1 集群架构设计 / Cluster Architecture Design

#### 1.1.1 高可用集群架构 / High Availability Cluster Architecture

**架构模型：**

```yaml
# 高可用Kubernetes集群架构
apiVersion: v1
kind: Cluster
metadata:
  name: ha-cluster
spec:
  controlPlane:
    replicas: 3
    nodes:
      - name: master-1
        ip: 192.168.1.10
        role: control-plane
      - name: master-2
        ip: 192.168.1.11
        role: control-plane
      - name: master-3
        ip: 192.168.1.12
        role: control-plane
  workerNodes:
    - name: worker-1
      ip: 192.168.1.20
      resources:
        cpu: "8"
        memory: "16Gi"
    - name: worker-2
      ip: 192.168.1.21
      resources:
        cpu: "8"
        memory: "16Gi"
```

**负载均衡配置：**

```yaml
# 负载均衡器配置
apiVersion: v1
kind: Service
metadata:
  name: api-gateway-lb
spec:
  type: LoadBalancer
  ports:
    - port: 80
      targetPort: 8080
  selector:
    app: api-gateway
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600
```

#### 1.1.2 多区域部署架构 / Multi-Region Deployment Architecture

**区域配置：**

```yaml
# 多区域部署配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: multi-region-config
data:
  regions: |
    - name: us-west-1
      endpoint: https://us-west-1.api.example.com
      latency: 50ms
    - name: us-east-1
      endpoint: https://us-east-1.api.example.com
      latency: 30ms
    - name: eu-west-1
      endpoint: https://eu-west-1.api.example.com
      latency: 100ms
```

### 1.2 应用部署实践 / Application Deployment Practice

#### 1.2.1 微服务部署策略 / Microservice Deployment Strategy

**蓝绿部署：**

```yaml
# 蓝绿部署配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service-blue
  labels:
    version: blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: user-service
      version: blue
  template:
    metadata:
      labels:
        app: user-service
        version: blue
    spec:
      containers:
      - name: user-service
        image: user-service:v1.0.0
        ports:
        - containerPort: 8080
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 20
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service-green
  labels:
    version: green
spec:
  replicas: 0  # 初始为0，准备切换
  selector:
    matchLabels:
      app: user-service
      version: green
  template:
    metadata:
      labels:
        app: user-service
        version: green
    spec:
      containers:
      - name: user-service
        image: user-service:v1.1.0
        ports:
        - containerPort: 8080
```

**金丝雀部署：**

```yaml
# 金丝雀部署配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service-canary
spec:
  replicas: 1  # 少量实例进行测试
  selector:
    matchLabels:
      app: user-service
      version: canary
  template:
    metadata:
      labels:
        app: user-service
        version: canary
    spec:
      containers:
      - name: user-service
        image: user-service:v1.2.0
        ports:
        - containerPort: 8080
        env:
        - name: CANARY_FLAG
          value: "true"
```

#### 1.2.2 配置管理实践 / Configuration Management Practice

**ConfigMap配置：**

```yaml
# 应用配置管理
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  database_url: "postgresql://user:pass@db:5432/app"
  redis_url: "redis://redis:6379"
  log_level: "INFO"
  api_timeout: "30s"
  cache_ttl: "3600"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: feature-flags
data:
  new_ui_enabled: "true"
  beta_features: "false"
  maintenance_mode: "false"
```

**Secret管理：**

```yaml
# 敏感信息管理
apiVersion: v1
kind: Secret
metadata:
  name: app-secrets
type: Opaque
data:
  database_password: cGFzc3dvcmQxMjM=  # base64编码
  api_key: YXBpX2tleV8xMjM0NTY=        # base64编码
  jwt_secret: and0X3NlY3JldF8xMjM=     # base64编码
```

### 1.3 自动扩缩容实践 / Auto-Scaling Practice

#### 1.3.1 HPA配置 / Horizontal Pod Autoscaler Configuration

**CPU和内存扩缩容：**

```yaml
# 水平Pod自动扩缩容
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: user-service-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

**自定义指标扩缩容：**

```yaml
# 基于自定义指标的扩缩容
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-gateway-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-gateway
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: v1
        kind: Service
        name: api-gateway
      target:
        type: AverageValue
        averageValue: 1000
  - type: Object
    object:
      metric:
        name: error-rate
      describedObject:
        apiVersion: v1
        kind: Service
        name: api-gateway
      target:
        type: AverageValue
        averageValue: 0.05
```

#### 1.3.2 VPA配置 / Vertical Pod Autoscaler Configuration

**垂直Pod自动扩缩容：**

```yaml
# 垂直Pod自动扩缩容
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: user-service-vpa
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: user-service
  updatePolicy:
    updateMode: "Auto"
  resourcePolicy:
    containerPolicies:
    - containerName: '*'
      minAllowed:
        cpu: 100m
        memory: 50Mi
      maxAllowed:
        cpu: 1
        memory: 500Mi
      controlledValues: RequestsAndLimits
```

### 1.4 网络策略实践 / Network Policy Practice

#### 1.4.1 网络隔离策略 / Network Isolation Policy

**服务间通信控制：**

```yaml
# 网络策略配置
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: user-service-network-policy
spec:
  podSelector:
    matchLabels:
      app: user-service
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: api-gateway
    ports:
    - protocol: TCP
      port: 8080
  - from:
    - podSelector:
        matchLabels:
          app: admin-panel
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: database
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
```

#### 1.4.2 服务网格集成 / Service Mesh Integration

**Istio服务网格配置：**

```yaml
# Istio VirtualService配置
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: user-service-vs
spec:
  hosts:
  - user-service
  http:
  - route:
    - destination:
        host: user-service
        subset: v1
      weight: 90
    - destination:
        host: user-service
        subset: v2
      weight: 10
    retries:
      attempts: 3
      perTryTimeout: 2s
    timeout: 10s
    fault:
      delay:
        percentage:
          value: 5
        fixedDelay: 2s
---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: user-service-dr
spec:
  host: user-service
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
    trafficPolicy:
      connectionPool:
        tcp:
          maxConnections: 100
        http:
          http1MaxPendingRequests: 1024
          maxRequestsPerConnection: 10
```

### 1.5 监控与日志实践 / Monitoring and Logging Practice

#### 1.5.1 Prometheus监控配置 / Prometheus Monitoring Configuration

**监控指标收集：**

```yaml
# Prometheus ServiceMonitor配置
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: user-service-monitor
  labels:
    team: backend
spec:
  selector:
    matchLabels:
      app: user-service
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
    scrapeTimeout: 10s
  - port: health
    interval: 30s
    path: /health
    scrapeTimeout: 5s
```

**告警规则配置：**

```yaml
# Prometheus告警规则
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: user-service-alerts
  labels:
    team: backend
spec:
  groups:
  - name: user-service
    rules:
    - alert: HighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value }}"
    - alert: HighLatency
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "High latency detected"
        description: "95th percentile latency is {{ $value }}s"
```

#### 1.5.2 日志收集配置 / Log Collection Configuration

**Fluentd日志收集：**

```yaml
# Fluentd DaemonSet配置
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: logging
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      serviceAccount: fluentd
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1.14-debian-elasticsearch7-1
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        - name: FLUENT_ELASTICSEARCH_SCHEME
          value: "http"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
```

## 2. Docker Swarm编排实践 / Docker Swarm Orchestration Practice

### 2.1 集群管理 / Cluster Management

#### 2.1.1 集群初始化 / Cluster Initialization

**管理节点配置：**

```bash
# 初始化Swarm集群
docker swarm init --advertise-addr 192.168.1.10

# 获取加入令牌
docker swarm join-token manager
docker swarm join-token worker
```

**节点加入集群：**

```bash
# 管理节点加入
docker swarm join --token SWMTKN-1-xxx 192.168.1.10:2377

# 工作节点加入
docker swarm join --token SWMTKN-1-xxx 192.168.1.10:2377
```

#### 2.1.2 服务部署 / Service Deployment

**微服务部署：**

```yaml
# docker-compose.yml
version: '3.8'
services:
  api-gateway:
    image: api-gateway:latest
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    ports:
      - "80:8080"
    networks:
      - app-network
    depends_on:
      - user-service
      - order-service

  user-service:
    image: user-service:latest
    deploy:
      replicas: 5
      placement:
        constraints:
          - node.role == worker
      update_config:
        parallelism: 2
        delay: 10s
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/users
      - REDIS_URL=redis://redis:6379
    networks:
      - app-network
    depends_on:
      - database
      - redis

  order-service:
    image: order-service:latest
    deploy:
      replicas: 3
      placement:
        constraints:
          - node.role == worker
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/orders
    networks:
      - app-network
    depends_on:
      - database

  database:
    image: postgres:13
    deploy:
      placement:
        constraints:
          - node.role == manager
    environment:
      - POSTGRES_DB=app
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - app-network

  redis:
    image: redis:6-alpine
    deploy:
      placement:
        constraints:
          - node.role == worker
    volumes:
      - redis_data:/data
    networks:
      - app-network

networks:
  app-network:
    driver: overlay
    attachable: true

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
```

### 2.2 服务发现与负载均衡 / Service Discovery and Load Balancing

#### 2.2.1 服务发现配置 / Service Discovery Configuration

**DNS服务发现：**

```yaml
# 服务发现配置
services:
  user-service:
    image: user-service:latest
    deploy:
      replicas: 3
      endpoint_mode: dnsrr  # DNS轮询模式
    networks:
      - app-network

  api-gateway:
    image: api-gateway:latest
    deploy:
      replicas: 2
    networks:
      - app-network
    # 通过服务名访问user-service
    command: ["--user-service-url=user-service:8080"]
```

#### 2.2.2 负载均衡策略 / Load Balancing Strategy

**VIP负载均衡：**

```yaml
# VIP模式负载均衡
services:
  user-service:
    image: user-service:latest
    deploy:
      replicas: 5
      endpoint_mode: vip  # 虚拟IP模式
      update_config:
        parallelism: 2
        delay: 10s
        order: start-first
    networks:
      - app-network
```

### 2.3 滚动更新策略 / Rolling Update Strategy

#### 2.3.1 蓝绿部署 / Blue-Green Deployment

**蓝绿部署脚本：**

```bash
#!/bin/bash
# 蓝绿部署脚本

SERVICE_NAME="user-service"
BLUE_VERSION="v1.0.0"
GREEN_VERSION="v1.1.0"

# 部署绿色版本
echo "Deploying green version..."
docker service update --image user-service:$GREEN_VERSION $SERVICE_NAME

# 等待服务健康
echo "Waiting for service health..."
sleep 30

# 检查服务状态
if docker service ls | grep -q "$SERVICE_NAME.*running"; then
    echo "Green deployment successful"
else
    echo "Green deployment failed, rolling back..."
    docker service update --image user-service:$BLUE_VERSION $SERVICE_NAME
    exit 1
fi
```

#### 2.3.2 金丝雀部署 / Canary Deployment

**金丝雀部署配置：**

```yaml
# 金丝雀部署
services:
  user-service:
    image: user-service:latest
    deploy:
      replicas: 10
      update_config:
        parallelism: 1
        delay: 30s
        failure_action: rollback
        monitor: 60s
        max_failure_ratio: 0.1
        order: start-first
```

## 3. Apache Mesos编排实践 / Apache Mesos Orchestration Practice

### 3.1 集群架构 / Cluster Architecture

#### 3.1.1 Mesos集群配置 / Mesos Cluster Configuration

**主节点配置：**

```bash
# Mesos主节点配置
mesos-master --ip=192.168.1.10 \
  --work_dir=/var/lib/mesos \
  --quorum=2 \
  --zk=zk://192.168.1.10:2181/mesos \
  --log_dir=/var/log/mesos
```

**从节点配置：**

```bash
# Mesos从节点配置
mesos-slave --master=zk://192.168.1.10:2181/mesos \
  --ip=192.168.1.20 \
  --hostname=worker-1 \
  --work_dir=/var/lib/mesos \
  --log_dir=/var/log/mesos \
  --resources=cpus:8;mem:16384;disk:100000
```

#### 3.1.2 Marathon应用编排 / Marathon Application Orchestration

**应用定义：**

```json
{
  "id": "/user-service",
  "cmd": "java -jar user-service.jar",
  "cpus": 0.5,
  "mem": 512,
  "disk": 0,
  "instances": 3,
  "container": {
    "type": "DOCKER",
    "docker": {
      "image": "user-service:latest",
      "network": "BRIDGE",
      "portMappings": [
        {
          "containerPort": 8080,
          "hostPort": 0,
          "servicePort": 10000,
          "protocol": "tcp"
        }
      ]
    }
  },
  "healthChecks": [
    {
      "protocol": "HTTP",
      "path": "/health",
      "portIndex": 0,
      "gracePeriodSeconds": 30,
      "intervalSeconds": 10,
      "timeoutSeconds": 5,
      "maxConsecutiveFailures": 3
    }
  ],
  "upgradeStrategy": {
    "minimumHealthCapacity": 0.5,
    "maximumOverCapacity": 0.2
  },
  "constraints": [
    ["hostname", "UNIQUE"]
  ],
  "env": {
    "DATABASE_URL": "postgresql://user:pass@db:5432/users",
    "REDIS_URL": "redis://redis:6379"
  }
}
```

### 3.2 资源管理 / Resource Management

#### 3.2.1 资源分配策略 / Resource Allocation Strategy

**资源预留配置：**

```json
{
  "id": "/high-priority-app",
  "cmd": "java -jar critical-app.jar",
  "cpus": 2.0,
  "mem": 2048,
  "instances": 2,
  "constraints": [
    ["cpus", "CLUSTER", "2.0"],
    ["mem", "CLUSTER", "2048"]
  ],
  "acceptedResourceRoles": ["high-priority"],
  "upgradeStrategy": {
    "minimumHealthCapacity": 1.0,
    "maximumOverCapacity": 0.0
  }
}
```

#### 3.2.2 资源隔离 / Resource Isolation

**容器资源限制：**

```json
{
  "id": "/isolated-app",
  "cmd": "java -jar isolated-app.jar",
  "cpus": 1.0,
  "mem": 1024,
  "instances": 1,
  "container": {
    "type": "DOCKER",
    "docker": {
      "image": "isolated-app:latest",
      "network": "USER",
      "parameters": [
        {
          "key": "cpuset-cpus",
          "value": "0-3"
        },
        {
          "key": "memory",
          "value": "1024m"
        }
      ]
    }
  }
}
```

## 4. 故障处理与恢复 / Fault Handling and Recovery

### 4.1 故障检测 / Fault Detection

#### 4.1.1 健康检查配置 / Health Check Configuration

**多层次健康检查：**

```yaml
# Kubernetes健康检查
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
spec:
  template:
    spec:
      containers:
      - name: user-service
        image: user-service:latest
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        startupProbe:
          httpGet:
            path: /startup
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 30
```

#### 4.1.2 故障检测算法 / Fault Detection Algorithm

**故障检测实现：**

```python
class FaultDetector:
    def __init__(self, service_name, health_check_url):
        self.service_name = service_name
        self.health_check_url = health_check_url
        self.failure_count = 0
        self.last_check_time = None
        self.failure_threshold = 3
        self.timeout = 5
        
    def check_health(self):
        """健康检查"""
        try:
            response = requests.get(
                self.health_check_url,
                timeout=self.timeout
            )
            if response.status_code == 200:
                self.failure_count = 0
                return True
            else:
                self.failure_count += 1
                return False
        except Exception as e:
            self.failure_count += 1
            return False
    
    def is_faulty(self):
        """判断是否故障"""
        return self.failure_count >= self.failure_threshold
    
    def reset(self):
        """重置故障计数"""
        self.failure_count = 0
```

### 4.2 故障恢复策略 / Fault Recovery Strategy

#### 4.2.1 自动恢复机制 / Automatic Recovery Mechanism

**Pod重启策略：**

```yaml
# 重启策略配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: user-service
spec:
  template:
    spec:
      restartPolicy: Always
      containers:
      - name: user-service
        image: user-service:latest
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 10"]
          postStart:
            exec:
              command: ["/bin/sh", "-c", "echo 'Container started'"]
```

#### 4.2.2 故障转移策略 / Failover Strategy

**故障转移配置：**

```yaml
# 故障转移配置
apiVersion: v1
kind: Service
metadata:
  name: user-service
spec:
  selector:
    app: user-service
  ports:
  - port: 80
    targetPort: 8080
  type: ClusterIP
---
apiVersion: v1
kind: Endpoints
metadata:
  name: user-service
subsets:
- addresses:
  - ip: 10.244.1.10
    targetRef:
      kind: Pod
      name: user-service-pod-1
  - ip: 10.244.1.11
    targetRef:
      kind: Pod
      name: user-service-pod-2
  ports:
  - port: 8080
    protocol: TCP
```

## 5. 性能优化实践 / Performance Optimization Practice

### 5.1 资源优化 / Resource Optimization

#### 5.1.1 资源限制配置 / Resource Limits Configuration

**精确资源分配：**

```yaml
# 资源限制配置
apiVersion: apps/v1
kind: Deployment
metadata:
  name: optimized-service
spec:
  template:
    spec:
      containers:
      - name: optimized-service
        image: optimized-service:latest
        resources:
          requests:
            cpu: "250m"
            memory: "256Mi"
            ephemeral-storage: "1Gi"
          limits:
            cpu: "500m"
            memory: "512Mi"
            ephemeral-storage: "2Gi"
        env:
        - name: GOMAXPROCS
          value: "2"
        - name: JAVA_OPTS
          value: "-Xms256m -Xmx512m"
```

#### 5.1.2 资源监控与调优 / Resource Monitoring and Tuning

**资源使用监控：**

```python
class ResourceMonitor:
    def __init__(self):
        self.metrics = {}
        
    def collect_metrics(self, pod_name):
        """收集资源指标"""
        try:
            # 获取Pod资源使用情况
            cpu_usage = self.get_cpu_usage(pod_name)
            memory_usage = self.get_memory_usage(pod_name)
            network_usage = self.get_network_usage(pod_name)
            
            self.metrics[pod_name] = {
                'cpu': cpu_usage,
                'memory': memory_usage,
                'network': network_usage,
                'timestamp': time.time()
            }
            
            return self.metrics[pod_name]
        except Exception as e:
            logger.error(f"Failed to collect metrics for {pod_name}: {e}")
            return None
    
    def analyze_resource_usage(self, pod_name):
        """分析资源使用情况"""
        if pod_name not in self.metrics:
            return None
            
        metrics = self.metrics[pod_name]
        
        # 计算资源利用率
        cpu_utilization = metrics['cpu']['usage'] / metrics['cpu']['limit']
        memory_utilization = metrics['memory']['usage'] / metrics['memory']['limit']
        
        # 生成优化建议
        recommendations = []
        
        if cpu_utilization < 0.3:
            recommendations.append("Consider reducing CPU limits")
        elif cpu_utilization > 0.8:
            recommendations.append("Consider increasing CPU limits")
            
        if memory_utilization < 0.4:
            recommendations.append("Consider reducing memory limits")
        elif memory_utilization > 0.9:
            recommendations.append("Consider increasing memory limits")
            
        return {
            'cpu_utilization': cpu_utilization,
            'memory_utilization': memory_utilization,
            'recommendations': recommendations
        }
```

### 5.2 网络优化 / Network Optimization

#### 5.2.1 网络策略优化 / Network Policy Optimization

**网络性能优化：**

```yaml
# 网络优化配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: network-optimization
data:
  tcp_keepalive: "true"
  tcp_keepalive_time: "300"
  tcp_keepalive_intvl: "75"
  tcp_keepalive_probes: "9"
  tcp_max_syn_backlog: "4096"
  tcp_fin_timeout: "30"
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: network-optimizer
spec:
  selector:
    matchLabels:
      name: network-optimizer
  template:
    metadata:
      labels:
        name: network-optimizer
    spec:
      hostNetwork: true
      containers:
      - name: network-optimizer
        image: network-optimizer:latest
        securityContext:
          privileged: true
        volumeMounts:
        - name: sysctl
          mountPath: /host/proc/sys
      volumes:
      - name: sysctl
        hostPath:
          path: /proc/sys
```

## 6. 安全实践 / Security Practice

### 6.1 容器安全 / Container Security

#### 6.1.1 安全策略配置 / Security Policy Configuration

**Pod安全策略：**

```yaml
# Pod安全策略
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: restricted-psp
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  hostNetwork: false
  hostIPC: false
  hostPID: false
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'RunAsAny'
  supplementalGroups:
    rule: 'MustRunAs'
    ranges:
      - min: 1
        max: 65535
  fsGroup:
    rule: 'MustRunAs'
    ranges:
      - min: 1
        max: 65535
  readOnlyRootFilesystem: true
```

#### 6.1.2 镜像安全扫描 / Image Security Scanning

**安全扫描配置：**

```yaml
# 镜像安全扫描
apiVersion: batch/v1
kind: CronJob
metadata:
  name: image-scanner
spec:
  schedule: "0 2 * * *"  # 每天凌晨2点执行
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: scanner
            image: trivy:latest
            command:
            - /bin/sh
            - -c
            - |
              for image in $(kubectl get pods -o jsonpath='{.items[*].spec.containers[*].image}' | tr ' ' '\n' | sort | uniq); do
                trivy image --severity HIGH,CRITICAL $image
              done
          restartPolicy: OnFailure
```

### 6.2 网络安全 / Network Security

#### 6.2.1 网络策略实施 / Network Policy Implementation

**严格网络策略：**

```yaml
# 严格网络策略
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-specific-traffic
spec:
  podSelector:
    matchLabels:
      app: user-service
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: api-gateway
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: database
    ports:
    - protocol: TCP
      port: 5432
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
```

## 7. 最佳实践总结 / Best Practices Summary

### 7.1 部署最佳实践 / Deployment Best Practices

1. **渐进式部署**：使用蓝绿部署或金丝雀部署降低风险
2. **健康检查**：配置完善的健康检查机制
3. **资源管理**：合理设置资源请求和限制
4. **监控告警**：建立完善的监控和告警体系
5. **备份恢复**：制定数据备份和灾难恢复策略

### 7.2 运维最佳实践 / Operations Best Practices

1. **自动化运维**：尽可能自动化部署、监控、故障处理
2. **日志管理**：集中化日志收集和分析
3. **安全加固**：实施最小权限原则和安全策略
4. **性能优化**：持续监控和优化系统性能
5. **文档管理**：维护详细的操作文档和故障处理手册

### 7.3 团队协作最佳实践 / Team Collaboration Best Practices

1. **代码审查**：实施严格的代码审查流程
2. **测试策略**：建立完善的测试体系
3. **版本管理**：使用语义化版本控制
4. **知识分享**：定期进行技术分享和培训
5. **持续改进**：建立反馈机制和持续改进流程

## 参考文献 / References

1. Kubernetes Documentation. "Production Best Practices". <https://kubernetes.io/docs/setup/best-practices/>
2. Docker Documentation. "Swarm Mode Overview". <https://docs.docker.com/engine/swarm/>
3. Apache Mesos Documentation. "Mesos Architecture". <http://mesos.apache.org/documentation/latest/architecture/>
4. Istio Documentation. "Traffic Management". <https://istio.io/docs/concepts/traffic-management/>
5. Prometheus Documentation. "Configuration". <https://prometheus.io/docs/prometheus/latest/configuration/>
6. Fluentd Documentation. "Kubernetes". <https://docs.fluentd.org/container-deployment/kubernetes>
7. CNCF. "Cloud Native Security Whitepaper". <https://github.com/cncf/sig-security/blob/master/security-whitepaper/CNCF_cloud-native-security-whitepaper-Nov2020.pdf>
8. Google Cloud. "Kubernetes Best Practices". <https://cloud.google.com/kubernetes-engine/docs/best-practices>
9. AWS. "Amazon ECS Best Practices". <https://docs.aws.amazon.com/AmazonECS/latest/bestpracticesguide/>
10. Microsoft Azure. "Azure Kubernetes Service Best Practices". <https://docs.microsoft.com/en-us/azure/aks/best-practices>
