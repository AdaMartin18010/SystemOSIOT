# 13.1.1 神经形态计算基础 / Neuromorphic Computing Fundamentals


<!-- TOC START -->

- [13.1.1 神经形态计算基础 / Neuromorphic Computing Fundamentals](#1311-神经形态计算基础-neuromorphic-computing-fundamentals)
  - [13.1.1.1 神经形态计算理论基础 / Neuromorphic Computing Theory](#13111-神经形态计算理论基础-neuromorphic-computing-theory)
    - [13.1.1.1.1 生物神经系统建模 / Biological Neural System Modeling](#131111-生物神经系统建模-biological-neural-system-modeling)

<!-- TOC END -->

## 13.1.1.1 神经形态计算理论基础 / Neuromorphic Computing Theory

### 13.1.1.1.1 生物神经系统建模 / Biological Neural System Modeling

**神经形态计算原理：**

```text
神经形态计算架构 (Neuromorphic Computing Architecture)
    ├── 脉冲神经网络 (Spiking Neural Networks)
    │   ├── LIF神经元模型
    │   ├── 突触可塑性
    │   ├── STDP学习规则
    │   └── 时间编码机制
    │
    ├── 神经形态芯片 (Neuromorphic Chips)
    │   ├── Intel Loihi
    │   ├── IBM TrueNorth
    │   ├── SpiNNaker
    │   └── Akida处理器
    │
    ├── 认知架构 (Cognitive Architecture)
    │   ├── 感知处理
    │   ├── 记忆系统
    │   ├── 决策机制
    │   └── 学习适应
    │
    └── 类脑计算范式 (Brain-Inspired Computing)
        ├── 事件驱动处理
        ├── 异步计算
        ├── 低功耗设计
        └── 容错机制
```

**神经形态计算系统核心实现：**

```rust
use std::collections::{HashMap, VecDeque};
use std::sync::{Arc, Mutex, RwLock};
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tokio::sync::mpsc;
use serde::{Serialize, Deserialize};
use nalgebra::{DVector, DMatrix};

// 脉冲神经网络核心组件
#[derive(Debug, Clone)]
pub struct SpikingNeuralNetwork {
    pub network_id: String,
    pub neurons: Vec<SpikingNeuron>,
    pub synapses: Vec<Synapse>,
    pub layers: Vec<NetworkLayer>,
    pub learning_rules: Vec<LearningRule>,
    pub simulation_time_step: Duration,
    pub global_time: u64,
    pub network_topology: NetworkTopology,
}

// 脉冲神经元模型
#[derive(Debug, Clone)]
pub struct SpikingNeuron {
    pub neuron_id: String,
    pub neuron_type: NeuronType,
    pub membrane_potential: f64,
    pub threshold_potential: f64,
    pub resting_potential: f64,
    pub refractory_period: Duration,
    pub last_spike_time: Option<u64>,
    pub current_input: f64,
    pub leak_conductance: f64,
    pub capacitance: f64,
    pub parameters: NeuronParameters,
    pub spike_history: VecDeque<u64>,
    pub state: NeuronState,
}

#[derive(Debug, Clone)]
pub enum NeuronType {
    LeakyIntegrateAndFire,
    AdaptiveExponential,
    IzhikevichModel,
    HodgkinHuxley,
    PoissonSpike,
    InputNeuron,
    OutputNeuron,
}

#[derive(Debug, Clone)]
pub struct NeuronParameters {
    pub tau_membrane: f64,      // 膜时间常数
    pub tau_refractory: f64,    // 不应期时间常数
    pub tau_adaptation: f64,    // 适应时间常数
    pub adaptation_strength: f64, // 适应强度
    pub noise_amplitude: f64,   // 噪声幅度
    pub spike_shape: SpikeShape,
}

#[derive(Debug, Clone)]
pub enum SpikeShape {
    Delta,
    Exponential { tau: f64 },
    Alpha { tau: f64 },
    Custom { waveform: Vec<f64> },
}

#[derive(Debug, Clone)]
pub enum NeuronState {
    Resting,
    Integrating,
    Spiking,
    Refractory,
    Adapting,
}

impl SpikingNeuron {
    pub fn new(neuron_id: String, neuron_type: NeuronType) -> Self {
        Self {
            neuron_id,
            neuron_type,
            membrane_potential: -70.0, // mV
            threshold_potential: -55.0, // mV
            resting_potential: -70.0,  // mV
            refractory_period: Duration::from_millis(2),
            last_spike_time: None,
            current_input: 0.0,
            leak_conductance: 10.0,     // nS
            capacitance: 100.0,         // pF
            parameters: NeuronParameters::default(),
            spike_history: VecDeque::with_capacity(1000),
            state: NeuronState::Resting,
        }
    }
    
    pub fn update(&mut self, dt: f64, current_time: u64) -> bool {
        // 检查是否在不应期
        if let Some(last_spike) = self.last_spike_time {
            let time_since_spike = current_time - last_spike;
            if Duration::from_nanos(time_since_spike) < self.refractory_period {
                self.state = NeuronState::Refractory;
                self.membrane_potential = self.resting_potential;
                return false;
            }
        }
        
        // 根据神经元类型更新膜电位
        match self.neuron_type {
            NeuronType::LeakyIntegrateAndFire => self.update_lif(dt),
            NeuronType::AdaptiveExponential => self.update_adaptive_exponential(dt),
            NeuronType::IzhikevichModel => self.update_izhikevich(dt),
            NeuronType::PoissonSpike => return self.update_poisson(current_time),
            _ => self.update_lif(dt),
        }
        
        // 检查是否发放脉冲
        if self.membrane_potential >= self.threshold_potential {
            self.fire_spike(current_time);
            return true;
        }
        
        false
    }
    
    fn update_lif(&mut self, dt: f64) {
        // Leaky Integrate-and-Fire模型
        let tau_m = self.parameters.tau_membrane;
        let leak_current = -self.leak_conductance * (self.membrane_potential - self.resting_potential);
        let total_current = self.current_input + leak_current;
        
        let dv_dt = total_current / self.capacitance;
        self.membrane_potential += dv_dt * dt;
        
        // 添加膜电位噪声
        if self.parameters.noise_amplitude > 0.0 {
            let noise = self.generate_noise() * self.parameters.noise_amplitude;
            self.membrane_potential += noise * dt.sqrt();
        }
        
        self.state = NeuronState::Integrating;
    }
    
    fn update_adaptive_exponential(&mut self, dt: f64) {
        // 自适应指数积分发放模型
        let v_thresh = self.threshold_potential;
        let delta_t = 2.0; // 锐度参数
        
        // 指数项
        let exp_term = if self.membrane_potential < v_thresh - 5.0 * delta_t {
            0.0
        } else {
            delta_t * ((self.membrane_potential - v_thresh) / delta_t).exp()
        };
        
        let leak_current = -self.leak_conductance * (self.membrane_potential - self.resting_potential);
        let exponential_current = self.leak_conductance * exp_term;
        let total_current = self.current_input + leak_current + exponential_current;
        
        let dv_dt = total_current / self.capacitance;
        self.membrane_potential += dv_dt * dt;
    }
    
    fn update_izhikevich(&mut self, dt: f64) {
        // Izhikevich神经元模型
        let a = 0.02; // 恢复变量时间尺度
        let b = 0.2;  // 恢复变量敏感性
        let c = -65.0; // 重置后膜电位
        let d = 8.0;   // 恢复变量重置
        
        let v = self.membrane_potential;
        let u = self.current_input; // 简化：使用current_input作为恢复变量
        
        let dv_dt = 0.04 * v * v + 5.0 * v + 140.0 - u + self.current_input;
        let du_dt = a * (b * v - u);
        
        self.membrane_potential += dv_dt * dt;
        self.current_input += du_dt * dt; // 更新恢复变量
    }
    
    fn update_poisson(&mut self, current_time: u64) -> bool {
        // 泊松脉冲神经元
        let rate = self.current_input.max(0.0); // Hz
        let dt = 0.001; // 1ms
        let probability = rate * dt;
        
        let random = (current_time % 1000) as f64 / 1000.0;
        if random < probability {
            self.fire_spike(current_time);
            return true;
        }
        false
    }
    
    fn fire_spike(&mut self, current_time: u64) {
        self.last_spike_time = Some(current_time);
        self.spike_history.push_back(current_time);
        
        // 保持脉冲历史大小
        if self.spike_history.len() > 1000 {
            self.spike_history.pop_front();
        }
        
        // 重置膜电位
        self.membrane_potential = self.resting_potential;
        self.state = NeuronState::Spiking;
        
        println!("Neuron {} fired at time {}", self.neuron_id, current_time);
    }
    
    fn generate_noise(&self) -> f64 {
        // 简化的高斯噪声生成
        let u1 = (SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos() % 1000) as f64 / 1000.0;
        let u2 = (SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos() % 1000) as f64 / 1000.0;
        
        // Box-Muller变换
        (-2.0 * u1.ln()).sqrt() * (2.0 * std::f64::consts::PI * u2).cos()
    }
    
    pub fn add_input_current(&mut self, current: f64) {
        self.current_input += current;
    }
    
    pub fn reset_input(&mut self) {
        self.current_input = 0.0;
    }
    
    pub fn get_spike_rate(&self, time_window: Duration) -> f64 {
        let current_time = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos() as u64;
        let window_start = current_time.saturating_sub(time_window.as_nanos() as u64);
        
        let spike_count = self.spike_history.iter()
            .filter(|&&spike_time| spike_time >= window_start)
            .count();
        
        spike_count as f64 / time_window.as_secs_f64()
    }
}

impl Default for NeuronParameters {
    fn default() -> Self {
        Self {
            tau_membrane: 20.0,      // ms
            tau_refractory: 2.0,     // ms
            tau_adaptation: 100.0,   // ms
            adaptation_strength: 0.0,
            noise_amplitude: 0.1,
            spike_shape: SpikeShape::Delta,
        }
    }
}

// 突触连接
#[derive(Debug, Clone)]
pub struct Synapse {
    pub synapse_id: String,
    pub pre_neuron_id: String,
    pub post_neuron_id: String,
    pub weight: f64,
    pub delay: Duration,
    pub synapse_type: SynapseType,
    pub plasticity: SynapticPlasticity,
    pub transmission_probability: f64,
    pub last_update_time: u64,
    pub trace_pre: f64,  // 突触前迹
    pub trace_post: f64, // 突触后迹
}

#[derive(Debug, Clone)]
pub enum SynapseType {
    Excitatory,
    Inhibitory,
    AMPA,
    NMDA,
    GABA_A,
    GABA_B,
    Electrical, // 电突触
}

#[derive(Debug, Clone)]
pub struct SynapticPlasticity {
    pub plasticity_type: PlasticityType,
    pub learning_rate: f64,
    pub tau_pre: f64,   // 突触前迹时间常数
    pub tau_post: f64,  // 突触后迹时间常数
    pub a_plus: f64,    // LTP幅度
    pub a_minus: f64,   // LTD幅度
    pub weight_bounds: (f64, f64), // 权重边界
}

#[derive(Debug, Clone)]
pub enum PlasticityType {
    STDP,           // 脉冲时间依赖可塑性
    RateBasedHebb,  // 基于发放率的Hebb学习
    BCM,            // BCM规则
    Homeostatic,    // 稳态可塑性
    MetaPlastic,    // 元可塑性
    None,
}

impl Synapse {
    pub fn new(synapse_id: String, pre_id: String, post_id: String) -> Self {
        Self {
            synapse_id,
            pre_neuron_id: pre_id,
            post_neuron_id: post_id,
            weight: 1.0,
            delay: Duration::from_millis(1),
            synapse_type: SynapseType::Excitatory,
            plasticity: SynapticPlasticity::default(),
            transmission_probability: 1.0,
            last_update_time: 0,
            trace_pre: 0.0,
            trace_post: 0.0,
        }
    }
    
    pub fn transmit_spike(&self, spike_time: u64) -> Option<SynapticEvent> {
        // 检查传输概率
        let random = (spike_time % 1000) as f64 / 1000.0;
        if random > self.transmission_probability {
            return None;
        }
        
        let arrival_time = spike_time + self.delay.as_nanos() as u64;
        
        Some(SynapticEvent {
            arrival_time,
            synapse_id: self.synapse_id.clone(),
            weight: self.weight,
            synapse_type: self.synapse_type.clone(),
        })
    }
    
    pub fn update_plasticity(&mut self, pre_spike_time: Option<u64>, post_spike_time: Option<u64>, current_time: u64) {
        match self.plasticity.plasticity_type {
            PlasticityType::STDP => self.update_stdp(pre_spike_time, post_spike_time, current_time),
            PlasticityType::RateBasedHebb => self.update_hebb_rate(current_time),
            PlasticityType::Homeostatic => self.update_homeostatic(current_time),
            _ => {}
        }
    }
    
    fn update_stdp(&mut self, pre_spike: Option<u64>, post_spike: Option<u64>, current_time: u64) {
        let dt = (current_time - self.last_update_time) as f64 * 1e-9; // 转换为秒
        
        // 更新突触迹
        self.trace_pre *= (-dt / self.plasticity.tau_pre).exp();
        self.trace_post *= (-dt / self.plasticity.tau_post).exp();
        
        // 处理突触前脉冲
        if let Some(_) = pre_spike {
            self.trace_pre += 1.0;
            // LTD: 突触前脉冲时减小权重（如果最近有突触后脉冲）
            let weight_change = -self.plasticity.a_minus * self.trace_post;
            self.weight += self.plasticity.learning_rate * weight_change;
        }
        
        // 处理突触后脉冲
        if let Some(_) = post_spike {
            self.trace_post += 1.0;
            // LTP: 突触后脉冲时增大权重（如果最近有突触前脉冲）
            let weight_change = self.plasticity.a_plus * self.trace_pre;
            self.weight += self.plasticity.learning_rate * weight_change;
        }
        
        // 权重边界约束
        self.weight = self.weight.clamp(self.plasticity.weight_bounds.0, self.plasticity.weight_bounds.1);
        
        self.last_update_time = current_time;
    }
    
    fn update_hebb_rate(&mut self, current_time: u64) {
        // 基于发放率的Hebb学习规则
        // 简化实现：权重变化正比于突触前后神经元的活动相关性
        let dt = (current_time - self.last_update_time) as f64 * 1e-9;
        
        // 这里需要访问神经元的发放率，简化处理
        let correlation = self.trace_pre * self.trace_post;
        let weight_change = self.plasticity.learning_rate * correlation * dt;
        
        self.weight += weight_change;
        self.weight = self.weight.clamp(self.plasticity.weight_bounds.0, self.plasticity.weight_bounds.1);
        
        self.last_update_time = current_time;
    }
    
    fn update_homeostatic(&mut self, current_time: u64) {
        // 稳态可塑性：维持神经元活动在目标水平
        let dt = (current_time - self.last_update_time) as f64 * 1e-9;
        let target_rate = 10.0; // Hz
        let current_rate = self.trace_post / dt; // 简化的发放率估计
        
        let rate_error = target_rate - current_rate;
        let weight_change = self.plasticity.learning_rate * rate_error * dt;
        
        self.weight += weight_change;
        self.weight = self.weight.clamp(self.plasticity.weight_bounds.0, self.plasticity.weight_bounds.1);
        
        self.last_update_time = current_time;
    }
}

impl Default for SynapticPlasticity {
    fn default() -> Self {
        Self {
            plasticity_type: PlasticityType::STDP,
            learning_rate: 0.01,
            tau_pre: 20.0,   // ms
            tau_post: 20.0,  // ms
            a_plus: 1.0,
            a_minus: 1.0,
            weight_bounds: (0.0, 10.0),
        }
    }
}

#[derive(Debug, Clone)]
pub struct SynapticEvent {
    pub arrival_time: u64,
    pub synapse_id: String,
    pub weight: f64,
    pub synapse_type: SynapseType,
}

// 网络层结构
#[derive(Debug, Clone)]
pub struct NetworkLayer {
    pub layer_id: String,
    pub neuron_ids: Vec<String>,
    pub layer_type: LayerType,
    pub activation_function: ActivationFunction,
    pub lateral_connections: bool,
}

#[derive(Debug, Clone)]
pub enum LayerType {
    Input,
    Hidden,
    Output,
    Recurrent,
    Convolutional,
    Pooling,
}

#[derive(Debug, Clone)]
pub enum ActivationFunction {
    Spike,
    ReLU,
    Sigmoid,
    Tanh,
    Softmax,
}

// 学习规则
#[derive(Debug, Clone)]
pub enum LearningRule {
    STDP(STDPRule),
    Reinforcement(ReinforcementRule),
    Unsupervised(UnsupervisedRule),
    Supervised(SupervisedRule),
}

#[derive(Debug, Clone)]
pub struct STDPRule {
    pub tau_plus: f64,
    pub tau_minus: f64,
    pub a_plus: f64,
    pub a_minus: f64,
    pub weight_dependence: WeightDependence,
}

#[derive(Debug, Clone)]
pub enum WeightDependence {
    Additive,
    Multiplicative,
    PowerLaw { exponent: f64 },
}

#[derive(Debug, Clone)]
pub struct ReinforcementRule {
    pub reward_signal: f64,
    pub eligibility_trace_decay: f64,
    pub learning_rate: f64,
}

#[derive(Debug, Clone)]
pub struct UnsupervisedRule {
    pub rule_type: UnsupervisedType,
    pub learning_rate: f64,
    pub competition_strength: f64,
}

#[derive(Debug, Clone)]
pub enum UnsupervisedType {
    Hebbian,
    AntiHebbian,
    Competitive,
    SelfOrganizing,
}

#[derive(Debug, Clone)]
pub struct SupervisedRule {
    pub error_signal: f64,
    pub learning_rate: f64,
    pub momentum: f64,
}

// 网络拓扑
#[derive(Debug, Clone)]
pub enum NetworkTopology {
    FullyConnected,
    Sparse { connectivity: f64 },
    SmallWorld { rewiring_probability: f64 },
    ScaleFree { gamma: f64 },
    Hierarchical,
    Modular { num_modules: usize },
    Custom { adjacency_matrix: DMatrix<f64> },
}

impl SpikingNeuralNetwork {
    pub fn new(network_id: String) -> Self {
        Self {
            network_id,
            neurons: Vec::new(),
            synapses: Vec::new(),
            layers: Vec::new(),
            learning_rules: Vec::new(),
            simulation_time_step: Duration::from_millis(1),
            global_time: 0,
            network_topology: NetworkTopology::FullyConnected,
        }
    }
    
    pub fn add_neuron(&mut self, neuron: SpikingNeuron) {
        self.neurons.push(neuron);
    }
    
    pub fn add_synapse(&mut self, synapse: Synapse) {
        self.synapses.push(synapse);
    }
    
    pub fn create_layer(&mut self, layer_id: String, neuron_count: usize, neuron_type: NeuronType) -> String {
        let mut neuron_ids = Vec::new();
        
        for i in 0..neuron_count {
            let neuron_id = format!("{}_{}", layer_id, i);
            let neuron = SpikingNeuron::new(neuron_id.clone(), neuron_type.clone());
            neuron_ids.push(neuron_id);
            self.add_neuron(neuron);
        }
        
        let layer = NetworkLayer {
            layer_id: layer_id.clone(),
            neuron_ids,
            layer_type: LayerType::Hidden,
            activation_function: ActivationFunction::Spike,
            lateral_connections: false,
        };
        
        self.layers.push(layer);
        layer_id
    }
    
    pub fn connect_layers(&mut self, pre_layer_id: &str, post_layer_id: &str, connection_type: ConnectionType) {
        let pre_layer = self.layers.iter().find(|l| l.layer_id == pre_layer_id);
        let post_layer = self.layers.iter().find(|l| l.layer_id == post_layer_id);
        
        if let (Some(pre), Some(post)) = (pre_layer, post_layer) {
            match connection_type {
                ConnectionType::FullyConnected => {
                    for pre_neuron_id in &pre.neuron_ids {
                        for post_neuron_id in &post.neuron_ids {
                            let synapse_id = format!("{}_{}", pre_neuron_id, post_neuron_id);
                            let synapse = Synapse::new(synapse_id, pre_neuron_id.clone(), post_neuron_id.clone());
                            self.add_synapse(synapse);
                        }
                    }
                }
                ConnectionType::OneToOne => {
                    for (pre_id, post_id) in pre.neuron_ids.iter().zip(post.neuron_ids.iter()) {
                        let synapse_id = format!("{}_{}", pre_id, post_id);
                        let synapse = Synapse::new(synapse_id, pre_id.clone(), post_id.clone());
                        self.add_synapse(synapse);
                    }
                }
                ConnectionType::Random { probability } => {
                    for pre_neuron_id in &pre.neuron_ids {
                        for post_neuron_id in &post.neuron_ids {
                            let random = (self.global_time % 1000) as f64 / 1000.0;
                            if random < probability {
                                let synapse_id = format!("{}_{}", pre_neuron_id, post_neuron_id);
                                let synapse = Synapse::new(synapse_id, pre_neuron_id.clone(), post_neuron_id.clone());
                                self.add_synapse(synapse);
                            }
                        }
                    }
                }
            }
        }
    }
    
    pub async fn simulate_step(&mut self) -> NetworkSimulationResult {
        let dt = self.simulation_time_step.as_secs_f64();
        let mut spike_events = Vec::new();
        let mut synaptic_events = Vec::new();
        
        // 1. 更新所有神经元
        for neuron in &mut self.neurons {
            if neuron.update(dt, self.global_time) {
                spike_events.push(SpikeEvent {
                    neuron_id: neuron.neuron_id.clone(),
                    spike_time: self.global_time,
                });
                
                // 查找所有从这个神经元发出的突触
                for synapse in &self.synapses {
                    if synapse.pre_neuron_id == neuron.neuron_id {
                        if let Some(event) = synapse.transmit_spike(self.global_time) {
                            synaptic_events.push(event);
                        }
                    }
                }
            }
        }
        
        // 2. 处理突触事件
        for event in &synaptic_events {
            if let Some(post_neuron) = self.neurons.iter_mut()
                .find(|n| n.neuron_id == self.get_post_neuron_id(&event.synapse_id)) {
                
                let current = match event.synapse_type {
                    SynapseType::Excitatory => event.weight,
                    SynapseType::Inhibitory => -event.weight,
                    _ => event.weight,
                };
                
                post_neuron.add_input_current(current);
            }
        }
        
        // 3. 更新突触可塑性
        self.update_synaptic_plasticity(&spike_events);
        
        // 4. 重置神经元输入
        for neuron in &mut self.neurons {
            neuron.reset_input();
        }
        
        self.global_time += self.simulation_time_step.as_nanos() as u64;
        
        NetworkSimulationResult {
            simulation_time: self.global_time,
            spike_events,
            synaptic_events,
            total_spikes: spike_events.len(),
            network_activity: self.calculate_network_activity(),
        }
    }
    
    fn update_synaptic_plasticity(&mut self, spike_events: &[SpikeEvent]) {
        for synapse in &mut self.synapses {
            let pre_spike = spike_events.iter()
                .find(|event| event.neuron_id == synapse.pre_neuron_id)
                .map(|event| event.spike_time);
            
            let post_spike = spike_events.iter()
                .find(|event| event.neuron_id == synapse.post_neuron_id)
                .map(|event| event.spike_time);
            
            synapse.update_plasticity(pre_spike, post_spike, self.global_time);
        }
    }
    
    fn get_post_neuron_id(&self, synapse_id: &str) -> String {
        self.synapses.iter()
            .find(|s| s.synapse_id == synapse_id)
            .map(|s| s.post_neuron_id.clone())
            .unwrap_or_default()
    }
    
    fn calculate_network_activity(&self) -> f64 {
        let active_neurons = self.neurons.iter()
            .filter(|n| matches!(n.state, NeuronState::Spiking | NeuronState::Integrating))
            .count();
        
        active_neurons as f64 / self.neurons.len() as f64
    }
    
    pub fn encode_input(&mut self, input_data: &[f64], encoding_type: EncodingType) {
        match encoding_type {
            EncodingType::RateCode => self.rate_encode_input(input_data),
            EncodingType::TemporalCode => self.temporal_encode_input(input_data),
            EncodingType::PopulationCode => self.population_encode_input(input_data),
            EncodingType::SpikeTime => self.spike_time_encode_input(input_data),
        }
    }
    
    fn rate_encode_input(&mut self, input_data: &[f64]) {
        // 频率编码：输入值越大，神经元发放频率越高
        for (i, &value) in input_data.iter().enumerate() {
            if let Some(neuron) = self.neurons.get_mut(i) {
                if matches!(neuron.neuron_type, NeuronType::InputNeuron) {
                    let normalized_value = value.clamp(0.0, 1.0);
                    let spike_rate = normalized_value * 100.0; // 最大100Hz
                    neuron.current_input = spike_rate;
                }
            }
        }
    }
    
    fn temporal_encode_input(&mut self, input_data: &[f64]) {
        // 时间编码：输入值决定脉冲发放的时间
        for (i, &value) in input_data.iter().enumerate() {
            if let Some(neuron) = self.neurons.get_mut(i) {
                if matches!(neuron.neuron_type, NeuronType::InputNeuron) {
                    let normalized_value = value.clamp(0.0, 1.0);
                    let spike_delay = (1.0 - normalized_value) * 50.0; // 0-50ms延迟
                    
                    // 设置在特定时间发放脉冲
                    if self.global_time as f64 >= spike_delay {
                        neuron.current_input = 1000.0; // 强制发放
                    }
                }
            }
        }
    }
    
    fn population_encode_input(&mut self, input_data: &[f64]) {
        // 群体编码：多个神经元共同编码一个输入值
        const NEURONS_PER_INPUT: usize = 10;
        
        for (input_idx, &value) in input_data.iter().enumerate() {
            let start_idx = input_idx * NEURONS_PER_INPUT;
            let normalized_value = value.clamp(0.0, 1.0);
            
            for i in 0..NEURONS_PER_INPUT {
                if let Some(neuron) = self.neurons.get_mut(start_idx + i) {
                    let preferred_value = i as f64 / (NEURONS_PER_INPUT - 1) as f64;
                    let distance = (normalized_value - preferred_value).abs();
                    let activation = (-distance * 5.0).exp(); // 高斯激活
                    neuron.current_input = activation * 50.0; // 转换为输入电流
                }
            }
        }
    }
    
    fn spike_time_encode_input(&mut self, input_data: &[f64]) {
        // 精确脉冲时间编码
        for (i, &value) in input_data.iter().enumerate() {
            if let Some(neuron) = self.neurons.get_mut(i) {
                if matches!(neuron.neuron_type, NeuronType::InputNeuron) {
                    let normalized_value = value.clamp(0.0, 1.0);
                    // 更精确的时间编码
                    let spike_time = self.global_time + (normalized_value * 1000.0) as u64;
                    
                    if self.global_time == spike_time {
                        neuron.current_input = 1000.0;
                    }
                }
            }
        }
    }
}

#[derive(Debug, Clone)]
pub enum ConnectionType {
    FullyConnected,
    OneToOne,
    Random { probability: f64 },
}

#[derive(Debug, Clone)]
pub enum EncodingType {
    RateCode,       // 频率编码
    TemporalCode,   // 时间编码
    PopulationCode, // 群体编码
    SpikeTime,      // 脉冲时间编码
}

#[derive(Debug, Clone)]
pub struct SpikeEvent {
    pub neuron_id: String,
    pub spike_time: u64,
}

#[derive(Debug)]
pub struct NetworkSimulationResult {
    pub simulation_time: u64,
    pub spike_events: Vec<SpikeEvent>,
    pub synaptic_events: Vec<SynapticEvent>,
    pub total_spikes: usize,
    pub network_activity: f64,
}

// 神经形态芯片模拟器
#[derive(Debug)]
pub struct NeuromorphicChip {
    pub chip_id: String,
    pub chip_type: ChipType,
    pub core_count: usize,
    pub cores: Vec<NeuromorphicCore>,
    pub global_memory: GlobalMemory,
    pub event_router: EventRouter,
    pub power_management: PowerManagement,
    pub clock_frequency: f64, // Hz
}

#[derive(Debug, Clone)]
pub enum ChipType {
    Loihi,
    TrueNorth,
    SpiNNaker,
    Akida,
    Custom,
}

#[derive(Debug)]
pub struct NeuromorphicCore {
    pub core_id: String,
    pub local_snn: SpikingNeuralNetwork,
    pub local_memory: LocalMemory,
    pub spike_router: SpikeRouter,
    pub learning_engine: LearningEngine,
    pub power_state: PowerState,
}

#[derive(Debug)]
pub struct GlobalMemory {
    pub total_capacity: usize, // bytes
    pub used_capacity: usize,
    pub memory_banks: Vec<MemoryBank>,
    pub access_patterns: HashMap<String, AccessPattern>,
}

#[derive(Debug)]
pub struct MemoryBank {
    pub bank_id: String,
    pub capacity: usize,
    pub data: Vec<u8>,
    pub access_time: Duration,
}

#[derive(Debug)]
pub struct AccessPattern {
    pub pattern_type: AccessType,
    pub frequency: f64,
    pub locality: LocalityType,
}

#[derive(Debug)]
pub enum AccessType {
    Sequential,
    Random,
    Strided { stride: usize },
    Clustered,
}

#[derive(Debug)]
pub enum LocalityType {
    Temporal,
    Spatial,
    Mixed,
}

#[derive(Debug)]
pub struct LocalMemory {
    pub capacity: usize,
    pub synaptic_memory: Vec<u8>,
    pub neuron_state_memory: Vec<u8>,
    pub spike_history: VecDeque<u64>,
}

#[derive(Debug)]
pub struct SpikeRouter {
    pub routing_table: HashMap<String, Vec<String>>,
    pub packet_buffer: VecDeque<SpikePacket>,
    pub congestion_control: CongestionControl,
}

#[derive(Debug)]
pub struct SpikePacket {
    pub source_neuron: String,
    pub target_neurons: Vec<String>,
    pub spike_time: u64,
    pub packet_id: String,
    pub priority: PacketPriority,
}

#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord)]
pub enum PacketPriority {
    Critical = 1,
    High = 2,
    Normal = 3,
    Low = 4,
}

#[derive(Debug)]
pub struct CongestionControl {
    pub algorithm: CongestionAlgorithm,
    pub buffer_threshold: f64,
    pub drop_probability: f64,
}

#[derive(Debug)]
pub enum CongestionAlgorithm {
    DropTail,
    RandomEarlyDetection,
    AdaptiveBackpressure,
    PriorityBased,
}

#[derive(Debug)]
pub struct LearningEngine {
    pub supported_rules: Vec<LearningRule>,
    pub active_rule: Option<LearningRule>,
    pub learning_rate: f64,
    pub batch_size: usize,
    pub update_frequency: Duration,
}

#[derive(Debug, Clone)]
pub enum PowerState {
    Active,
    Idle,
    Sleep,
    PowerDown,
}

#[derive(Debug)]
pub struct EventRouter {
    pub routing_algorithm: RoutingAlgorithm,
    pub event_queue: VecDeque<NeuromorphicEvent>,
    pub bandwidth_mbps: f64,
    pub latency_ns: f64,
}

#[derive(Debug)]
pub enum RoutingAlgorithm {
    Unicast,
    Multicast,
    Broadcast,
    AdaptiveRouting,
    DimensionOrderRouting,
}

#[derive(Debug)]
pub struct NeuromorphicEvent {
    pub event_id: String,
    pub event_type: EventType,
    pub source_core: String,
    pub target_cores: Vec<String>,
    pub timestamp: u64,
    pub payload: Vec<u8>,
}

#[derive(Debug)]
pub enum EventType {
    Spike,
    Learning,
    Configuration,
    Synchronization,
    Error,
}

#[derive(Debug)]
pub struct PowerManagement {
    pub power_domains: Vec<PowerDomain>,
    pub dvfs_enabled: bool, // Dynamic Voltage and Frequency Scaling
    pub power_gating: bool,
    pub clock_gating: bool,
    pub total_power_consumption: f64, // watts
}

#[derive(Debug)]
pub struct PowerDomain {
    pub domain_id: String,
    pub voltage: f64,
    pub frequency: f64,
    pub components: Vec<String>,
    pub power_consumption: f64,
}

impl NeuromorphicChip {
    pub fn new(chip_id: String, chip_type: ChipType, core_count: usize) -> Self {
        let mut cores = Vec::new();
        
        for i in 0..core_count {
            let core_id = format!("core_{}", i);
            let core = NeuromorphicCore {
                core_id: core_id.clone(),
                local_snn: SpikingNeuralNetwork::new(format!("snn_{}", core_id)),
                local_memory: LocalMemory {
                    capacity: 1024 * 1024, // 1MB per core
                    synaptic_memory: vec![0; 512 * 1024],
                    neuron_state_memory: vec![0; 512 * 1024],
                    spike_history: VecDeque::with_capacity(10000),
                },
                spike_router: SpikeRouter {
                    routing_table: HashMap::new(),
                    packet_buffer: VecDeque::with_capacity(1000),
                    congestion_control: CongestionControl {
                        algorithm: CongestionAlgorithm::RandomEarlyDetection,
                        buffer_threshold: 0.8,
                        drop_probability: 0.1,
                    },
                },
                learning_engine: LearningEngine {
                    supported_rules: vec![LearningRule::STDP(STDPRule::default())],
                    active_rule: None,
                    learning_rate: 0.01,
                    batch_size: 32,
                    update_frequency: Duration::from_millis(10),
                },
                power_state: PowerState::Active,
            };
            cores.push(core);
        }
        
        Self {
            chip_id,
            chip_type,
            core_count,
            cores,
            global_memory: GlobalMemory {
                total_capacity: 256 * 1024 * 1024, // 256MB
                used_capacity: 0,
                memory_banks: vec![
                    MemoryBank {
                        bank_id: "bank_0".to_string(),
                        capacity: 128 * 1024 * 1024,
                        data: vec![0; 128 * 1024 * 1024],
                        access_time: Duration::from_nanos(10),
                    },
                    MemoryBank {
                        bank_id: "bank_1".to_string(),
                        capacity: 128 * 1024 * 1024,
                        data: vec![0; 128 * 1024 * 1024],
                        access_time: Duration::from_nanos(10),
                    },
                ],
                access_patterns: HashMap::new(),
            },
            event_router: EventRouter {
                routing_algorithm: RoutingAlgorithm::AdaptiveRouting,
                event_queue: VecDeque::with_capacity(10000),
                bandwidth_mbps: 1000.0,
                latency_ns: 1.0,
            },
            power_management: PowerManagement {
                power_domains: vec![
                    PowerDomain {
                        domain_id: "core_domain".to_string(),
                        voltage: 1.0,
                        frequency: 1e9, // 1GHz
                        components: (0..core_count).map(|i| format!("core_{}", i)).collect(),
                        power_consumption: 0.5, // watts per core
                    },
                    PowerDomain {
                        domain_id: "memory_domain".to_string(),
                        voltage: 1.2,
                        frequency: 800e6, // 800MHz
                        components: vec!["global_memory".to_string()],
                        power_consumption: 2.0,
                    },
                ],
                dvfs_enabled: true,
                power_gating: true,
                clock_gating: true,
                total_power_consumption: 0.0,
            },
            clock_frequency: 1e9,
        }
    }
    
    pub async fn simulate_cycle(&mut self) -> ChipSimulationResult {
        let cycle_start = SystemTime::now();
        let mut total_events = 0;
        let mut core_results = Vec::new();
        
        // 1. 并行模拟所有核心
        for core in &mut self.cores {
            let result = core.local_snn.simulate_step().await;
            total_events += result.total_spikes;
            core_results.push(result);
            
            // 生成核间通信事件
            self.generate_inter_core_events(core).await;
        }
        
        // 2. 路由事件
        self.route_events().await;
        
        // 3. 更新功耗
        self.update_power_consumption().await;
        
        // 4. 执行学习更新
        self.execute_learning_updates().await;
        
        let cycle_duration = SystemTime::now().duration_since(cycle_start).unwrap();
        
        ChipSimulationResult {
            cycle_time: cycle_duration,
            total_events,
            core_results,
            power_consumption: self.power_management.total_power_consumption,
            memory_utilization: self.calculate_memory_utilization(),
            network_congestion: self.calculate_network_congestion(),
        }
    }
    
    async fn generate_inter_core_events(&mut self, core: &NeuromorphicCore) {
        // 生成核间通信事件
        for spike_event in &core.local_snn.neurons {
            if spike_event.state == NeuronState::Spiking {
                let event = NeuromorphicEvent {
                    event_id: format!("event_{}", SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos()),
                    event_type: EventType::Spike,
                    source_core: core.core_id.clone(),
                    target_cores: vec!["core_1".to_string()], // 简化的目标核心选择
                    timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos() as u64,
                    payload: vec![],
                };
                
                self.event_router.event_queue.push_back(event);
            }
        }
    }
    
    async fn route_events(&mut self) {
        while let Some(event) = self.event_router.event_queue.pop_front() {
            match self.event_router.routing_algorithm {
                RoutingAlgorithm::Unicast => self.unicast_routing(&event).await,
                RoutingAlgorithm::Multicast => self.multicast_routing(&event).await,
                RoutingAlgorithm::AdaptiveRouting => self.adaptive_routing(&event).await,
                _ => {}
            }
        }
    }
    
    async fn unicast_routing(&mut self, event: &NeuromorphicEvent) {
        // 单播路由实现
        if let Some(target_core_id) = event.target_cores.first() {
            if let Some(target_core) = self.cores.iter_mut().find(|c| &c.core_id == target_core_id) {
                // 模拟网络延迟
                tokio::time::sleep(Duration::from_nanos(self.event_router.latency_ns as u64)).await;
                
                // 投递事件到目标核心
                println!("Event {} routed from {} to {}", 
                    event.event_id, event.source_core, target_core_id);
            }
        }
    }
    
    async fn multicast_routing(&mut self, event: &NeuromorphicEvent) {
        // 多播路由实现
        for target_core_id in &event.target_cores {
            if let Some(_target_core) = self.cores.iter_mut().find(|c| &c.core_id == target_core_id) {
                println!("Multicast event {} to {}", event.event_id, target_core_id);
            }
        }
    }
    
    async fn adaptive_routing(&mut self, event: &NeuromorphicEvent) {
        // 自适应路由：根据网络拥塞情况选择路由
        let congestion_level = self.calculate_network_congestion();
        
        if congestion_level < 0.5 {
            self.unicast_routing(event).await;
        } else {
            // 高拥塞时使用替代路径或缓存
            println!("High congestion, delaying event {}", event.event_id);
        }
    }
    
    async fn update_power_consumption(&mut self) {
        let mut total_power = 0.0;
        
        for domain in &mut self.power_management.power_domains {
            // 动态功耗计算
            let activity_factor = self.calculate_activity_factor(&domain.components);
            let dynamic_power = domain.voltage.powi(2) * domain.frequency * activity_factor;
            
            // 静态功耗
            let static_power = domain.voltage * 0.1; // 简化的漏电流功耗
            
            domain.power_consumption = dynamic_power + static_power;
            total_power += domain.power_consumption;
        }
        
        self.power_management.total_power_consumption = total_power;
        
        // DVFS优化
        if self.power_management.dvfs_enabled {
            self.optimize_voltage_frequency().await;
        }
    }
    
    fn calculate_activity_factor(&self, components: &[String]) -> f64 {
        // 计算组件活动因子
        let mut total_activity = 0.0;
        let mut component_count = 0;
        
        for component in components {
            if component.starts_with("core_") {
                if let Some(core) = self.cores.iter().find(|c| &c.core_id == component) {
                    total_activity += core.local_snn.calculate_network_activity();
                    component_count += 1;
                }
            }
        }
        
        if component_count > 0 {
            total_activity / component_count as f64
        } else {
            0.1 // 基础活动水平
        }
    }
    
    async fn optimize_voltage_frequency(&mut self) {
        for domain in &mut self.power_management.power_domains {
            let activity = self.calculate_activity_factor(&domain.components);
            
            // 根据活动水平调整电压和频率
            if activity < 0.3 {
                domain.voltage *= 0.9;
                domain.frequency *= 0.8;
            } else if activity > 0.8 {
                domain.voltage *= 1.05;
                domain.frequency *= 1.1;
            }
            
            // 限制电压和频率范围
            domain.voltage = domain.voltage.clamp(0.7, 1.3);
            domain.frequency = domain.frequency.clamp(100e6, 2e9);
        }
    }
    
    async fn execute_learning_updates(&mut self) {
        for core in &mut self.cores {
            if let Some(learning_rule) = &core.learning_engine.active_rule {
                match learning_rule {
                    LearningRule::STDP(_) => {
                        // STDP学习已在网络仿真中处理
                    }
                    LearningRule::Reinforcement(rule) => {
                        self.apply_reinforcement_learning(core, rule).await;
                    }
                    _ => {}
                }
            }
        }
    }
    
    async fn apply_reinforcement_learning(&mut self, core: &mut NeuromorphicCore, rule: &ReinforcementRule) {
        // 强化学习更新
        let reward = rule.reward_signal;
        let learning_rate = rule.learning_rate;
        
        for synapse in &mut core.local_snn.synapses {
            // 更新适格迹
            let eligibility_decay = (-rule.eligibility_trace_decay).exp();
            
            // 简化的强化学习权重更新
            let weight_change = learning_rate * reward * eligibility_decay;
            synapse.weight += weight_change;
            synapse.weight = synapse.weight.clamp(0.0, 10.0);
        }
    }
    
    fn calculate_memory_utilization(&self) -> f64 {
        self.global_memory.used_capacity as f64 / self.global_memory.total_capacity as f64
    }
    
    fn calculate_network_congestion(&self) -> f64 {
        let buffer_utilization = self.event_router.event_queue.len() as f64 / 10000.0;
        buffer_utilization.clamp(0.0, 1.0)
    }
}

impl Default for STDPRule {
    fn default() -> Self {
        Self {
            tau_plus: 20.0,
            tau_minus: 20.0,
            a_plus: 1.0,
            a_minus: 1.0,
            weight_dependence: WeightDependence::Additive,
        }
    }
}

#[derive(Debug)]
pub struct ChipSimulationResult {
    pub cycle_time: Duration,
    pub total_events: usize,
    pub core_results: Vec<NetworkSimulationResult>,
    pub power_consumption: f64,
    pub memory_utilization: f64,
    pub network_congestion: f64,
}

// 认知架构
#[derive(Debug)]
pub struct CognitiveArchitecture {
    pub architecture_id: String,
    pub perception_system: PerceptionSystem,
    pub memory_system: MemorySystem,
    pub attention_system: AttentionSystem,
    pub decision_system: DecisionSystem,
    pub learning_system: LearningSystem,
    pub executive_control: ExecutiveControl,
    pub embodiment: EmbodimentInterface,
}

#[derive(Debug)]
pub struct PerceptionSystem {
    pub sensory_modules: Vec<SensoryModule>,
    pub feature_extractors: Vec<FeatureExtractor>,
    pub pattern_recognizers: Vec<PatternRecognizer>,
    pub perceptual_memory: PerceptualMemory,
}

#[derive(Debug)]
pub struct SensoryModule {
    pub module_id: String,
    pub modality: SensoryModality,
    pub input_snn: SpikingNeuralNetwork,
    pub preprocessing: PreprocessingPipeline,
    pub adaptation_mechanism: AdaptationMechanism,
}

#[derive(Debug, Clone)]
pub enum SensoryModality {
    Visual,
    Auditory,
    Tactile,
    Olfactory,
    Gustatory,
    Proprioceptive,
    Vestibular,
    Magnetic,
    Thermal,
}

#[derive(Debug)]
pub struct PreprocessingPipeline {
    pub filters: Vec<SensoryFilter>,
    pub normalization: NormalizationType,
    pub noise_reduction: NoiseReductionMethod,
}

#[derive(Debug)]
pub enum SensoryFilter {
    LowPass { cutoff_frequency: f64 },
    HighPass { cutoff_frequency: f64 },
    BandPass { low_freq: f64, high_freq: f64 },
    EdgeDetection,
    MotionDetection,
    ContrastEnhancement,
}

#[derive(Debug)]
pub enum NormalizationType {
    MinMax,
    ZScore,
    Robust,
    Adaptive,
}

#[derive(Debug)]
pub enum NoiseReductionMethod {
    GaussianFilter,
    MedianFilter,
    WienerFilter,
    AdaptiveFilter,
}

#[derive(Debug)]
pub struct AdaptationMechanism {
    pub adaptation_type: AdaptationType,
    pub time_constant: f64,
    pub adaptation_strength: f64,
}

#[derive(Debug)]
pub enum AdaptationType {
    SensoryAdaptation,
    GainControl,
    Habituation,
    Sensitization,
}

// 演示函数
pub async fn demonstrate_neuromorphic_computing() -> Result<(), NeuromorphicError> {
    println!("=== 神经形态计算系统演示 ===");
    
    // 1. 创建脉冲神经网络
    let mut snn = SpikingNeuralNetwork::new("demo_snn".to_string());
    
    // 2. 创建网络层
    let input_layer = snn.create_layer("input".to_string(), 10, NeuronType::InputNeuron);
    let hidden_layer = snn.create_layer("hidden".to_string(), 20, NeuronType::LeakyIntegrateAndFire);
    let output_layer = snn.create_layer("output".to_string(), 5, NeuronType::LeakyIntegrateAndFire);
    
    // 3. 连接层
    snn.connect_layers(&input_layer, &hidden_layer, ConnectionType::FullyConnected);
    snn.connect_layers(&hidden_layer, &output_layer, ConnectionType::Random { probability: 0.5 });
    
    println!("✅ 创建了包含 {} 个神经元和 {} 个突触的脉冲神经网络", 
        snn.neurons.len(), snn.synapses.len());
    
    // 4. 输入编码和仿真
    let input_data = vec![0.1, 0.5, 0.8, 0.3, 0.9, 0.2, 0.7, 0.4, 0.6, 0.1];
    snn.encode_input(&input_data, EncodingType::RateCode);
    
    println!("✅ 使用频率编码输入数据");
    
    // 5. 运行仿真
    let mut total_spikes = 0;
    for step in 0..100 {
        let result = snn.simulate_step().await;
        total_spikes += result.total_spikes;
        
        if step % 20 == 0 {
            println!("仿真步骤 {}: {} 个脉冲, 网络活动: {:.2}%", 
                step, result.total_spikes, result.network_activity * 100.0);
        }
    }
    
    println!("✅ 仿真完成，总共产生 {} 个脉冲", total_spikes);
    
    // 6. 创建神经形态芯片
    let mut chip = NeuromorphicChip::new("demo_chip".to_string(), ChipType::Loihi, 4);
    
    // 7. 芯片仿真
    let chip_result = chip.simulate_cycle().await;
    
    println!("✅ 神经形态芯片仿真:");
    println!("   - 仿真周期时间: {:?}", chip_result.cycle_time);
    println!("   - 总事件数: {}", chip_result.total_events);
    println!("   - 功耗: {:.2} W", chip_result.power_consumption);
    println!("   - 内存利用率: {:.2}%", chip_result.memory_utilization * 100.0);
    println!("   - 网络拥塞: {:.2}%", chip_result.network_congestion * 100.0);
    
    println!("=== 神经形态计算演示完成 ===");
    Ok(())
}

#[derive(Debug)]
pub enum NeuromorphicError {
    SimulationError,
    NetworkConfigurationError,
    HardwareError,
    MemoryError,
    RoutingError,
}

impl std::fmt::Display for NeuromorphicError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            NeuromorphicError::SimulationError => write!(f, "Neuromorphic simulation error"),
            NeuromorphicError::NetworkConfigurationError => write!(f, "Neural network configuration error"),
            NeuromorphicError::HardwareError => write!(f, "Neuromorphic hardware error"),
            NeuromorphicError::MemoryError => write!(f, "Memory access error"),
            NeuromorphicError::RoutingError => write!(f, "Event routing error"),
        }
    }
}

impl std::error::Error for NeuromorphicError {}
