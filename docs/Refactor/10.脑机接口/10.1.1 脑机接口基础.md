# 10.1.1 脑机接口基础 / Brain-Computer Interface Fundamentals

## 1. 脑机接口基础 / Foundations of Brain-Computer Interface

### 1.1 脑机接口定义 / Definition of Brain-Computer Interface

**脑机接口定义：**

- $BCI = \{Direct\ communication\ channel | Brain \leftrightarrow Computer\}$  
  脑机接口：大脑与计算机之间的直接通信通道。
- $Brain_{Signal} = \{Neural\ activity | Electrical, Magnetic, Metabolic\}$  
  脑信号：神经活动的电、磁、代谢信号。
- $Computer_{Interface} = \{Hardware, Software | Signal\ processing, Control\}$  
  计算机接口：信号处理和控制的硬件软件系统。

**BCI系统组成 / BCI System Components：**

- **信号采集 Signal Acquisition**：$Acquisition = \{Electrodes, Amplifiers, ADCs\}$
- **信号处理 Signal Processing**：$Processing = \{Filtering, Feature\ extraction, Classification\}$
- **控制输出 Control Output**：$Output = \{Cursor\ control, Device\ control, Communication\}$
- **反馈系统 Feedback System**：$Feedback = \{Visual, Auditory, Tactile\ feedback\}$

### 1.2 BCI分类 / BCI Classification

**按信号类型分类 / Classification by Signal Type：**

- **侵入式 Invasive**：$Invasive = \{Intracortical, ECoG, DBS\}$
- **半侵入式 Semi-invasive**：$Semi_{invasive} = \{ECoG, Subdural\}$
- **非侵入式 Non-invasive**：$Non_{invasive} = \{EEG, MEG, fNIRS\}$

**按应用领域分类 / Classification by Application：**

- **医疗康复 Medical Rehabilitation**：$Medical = \{Motor\ restoration, Communication\}$
- **增强功能 Enhancement**：$Enhancement = \{Cognitive\ augmentation, Gaming\}$
- **研究工具 Research Tool**：$Research = \{Neuroscience\ research, Brain\ mapping\}$

## 2. 神经信号处理 / Neural Signal Processing

### 2.1 脑电图信号 EEG Signals

**EEG信号特征 / EEG Signal Characteristics：**

- $EEG_{Frequency} = \{Delta(0.5-4Hz), Theta(4-8Hz), Alpha(8-13Hz), Beta(13-30Hz), Gamma(>30Hz)\}$
- $EEG_{Amplitude} = \{10-100\mu V\}$
- $EEG_{Resolution} = \{Temporal: 1ms, Spatial: 1cm\}$

**EEG信号预处理 / EEG Signal Preprocessing：**

- $Filtering = \{Bandpass(0.5-50Hz), Notch(50/60Hz), Artifact\ removal\}$
- $Segmentation = \{Epoch\ extraction, Event_{aligned}\}$
- $Normalization = \{Z_{score}, Min_{max}\ scaling\}$

### 2.2 特征提取 / Feature Extraction

**时域特征 Time Domain Features：**

- $Mean_{amplitude} = \frac{1}{N}\sum_{i=1}^{N} x_i$
- $Variance = \frac{1}{N-1}\sum_{i=1}^{N} (x_i - \bar{x})^2$
- $RMS = \sqrt{\frac{1}{N}\sum_{i=1}^{N} x_i^2}$
- $Peak_{to}_{peak} = max(x_i) - min(x_i)$

**频域特征 Frequency Domain Features：**

- $Power_{spectral}_{density} = |FFT(x)|^2$
- $Band_{power} = \int_{f1}^{f2} PSD(f) df$
- $Spectral_{entropy} = -\sum_{i} p_i \log(p_i)$
- $Peak_{frequency} = argmax_f PSD(f)$

**时频域特征 Time-Frequency Features：**

- $Wavelet_{coefficients} = W(a,b) = \int x(t)\psi_{a,b}(t)dt$
- $STFT = X(t,f) = \int x(\tau)w(t-\tau)e^{-j2\pi f\tau}d\tau$
- $Hilbert_{transform} = H(x(t)) = \frac{1}{\pi}P\int_{-\infty}^{\infty} \frac{x(\tau)}{t-\tau}d\tau$

### 2.3 空间滤波 / Spatial Filtering

**CSP算法 Common Spatial Patterns：**

- $CSP_{objective} = \max_w \frac{w^T C_1 w}{w^T C_2 w}$
- $CSP_{solution} = w = C_2^{-1}(C_1 - C_2)v$
- $CSP_{features} = \log(var(w_i^T X))$

**ICA算法 Independent Component Analysis：**

- $ICA_{model} = X = AS$
- $ICA_{objective} = \max I(S_1, S_2, ..., S_n)$
- $ICA_{solution} = W = A^{-1}$

## 3. 神经解码算法 / Neural Decoding Algorithms

### 3.1 线性分类器 Linear Classifiers

**线性判别分析 LDA：**

- $LDA_{discriminant} = w^T x + w_0$
- $LDA_{weights} = w = \Sigma^{-1}(\mu_1 - \mu_2)$
- $LDA_{threshold} = w_0 = -\frac{1}{2}(\mu_1 + \mu_2)^T \Sigma^{-1}(\mu_1 - \mu_2)$

**支持向量机 SVM：**

- $SVM_{objective} = \min_{w,b} \frac{1}{2}||w||^2 + C\sum_{i=1}^{N} \xi_i$
- $SVM_{constraints} = y_i(w^T x_i + b) \geq 1 - \xi_i$
- $SVM_{kernel} = K(x_i, x_j) = \phi(x_i)^T \phi(x_j)$

### 3.2 非线性分类器 Nonlinear Classifiers

**人工神经网络 ANN：**

- $ANN_{output} = f(\sum_{i=1}^{n} w_i x_i + b)$
- $ANN_{activation} = f(x) = \frac{1}{1 + e^{-x}}$ (Sigmoid)
- $ANN_{loss} = L = -\sum_{i=1}^{N} y_i \log(\hat{y}_i)$

**随机森林 Random Forest：**

- $RF_{prediction} = \frac{1}{T}\sum_{t=1}^{T} h_t(x)$
- $RF_{diversity} = \max_{t} \frac{1}{T}\sum_{i=1}^{T} I(h_t(x_i) \neq h_{t'}(x_i))$

### 3.3 回归算法 Regression Algorithms

**线性回归 Linear Regression：**

- $Linear_{model} = y = w^T x + b$
- $Linear_{loss} = L = \frac{1}{2N}\sum_{i=1}^{N} (y_i - \hat{y}_i)^2$
- $Linear_{solution} = w = (X^T X)^{-1} X^T y$

**卡尔曼滤波 Kalman Filter：**

- $KF_{predict} = \hat{x}_k^- = F_k \hat{x}_{k-1} + B_k u_k$
- $KF_{update} = \hat{x}_k = \hat{x}_k^- + K_k(z_k - H_k \hat{x}_k^-)$
- $KF_{gain} = K_k = P_k^- H_k^T(H_k P_k^- H_k^T + R_k)^{-1}$

## 4. 工程实现 / Engineering Implementation

```rust
use std::collections::{HashMap, VecDeque};
use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use serde::{Deserialize, Serialize};
use tokio::sync::mpsc;
use ndarray::{Array1, Array2, ArrayView1, ArrayView2};
use ndarray_linalg::{Eig, QR, SVD};

// BCI系统类型
#[derive(Debug, Clone, PartialEq)]
pub enum BCIType {
    Invasive,
    SemiInvasive,
    NonInvasive,
}

// 信号类型
#[derive(Debug, Clone, PartialEq)]
pub enum SignalType {
    EEG,
    ECoG,
    MEG,
    FNIRS,
    Intracortical,
}

// 电极类型
#[derive(Debug, Clone, PartialEq)]
pub enum ElectrodeType {
    Wet,
    Dry,
    Active,
    Passive,
}

// BCI系统
#[derive(Debug, Clone)]
pub struct BCISystem {
    pub id: String,
    pub name: String,
    pub bci_type: BCIType,
    pub signal_type: SignalType,
    pub electrodes: Vec<Electrode>,
    pub amplifiers: Vec<Amplifier>,
    pub processors: Vec<SignalProcessor>,
    pub decoders: Vec<NeuralDecoder>,
    pub controllers: Vec<Controller>,
    pub feedback_systems: Vec<FeedbackSystem>,
    pub configuration: BCIConfiguration,
    pub state: Arc<Mutex<BCIState>>,
}

#[derive(Debug, Clone)]
pub struct Electrode {
    pub id: String,
    pub name: String,
    pub electrode_type: ElectrodeType,
    pub position: (f32, f32, f32),
    pub impedance: f32,
    pub channel_number: u32,
    pub sampling_rate: u32,
    pub resolution: u32,
}

#[derive(Debug, Clone)]
pub struct Amplifier {
    pub id: String,
    pub name: String,
    pub gain: f32,
    pub bandwidth: (f32, f32),
    pub input_impedance: f32,
    pub noise_level: f32,
    pub channels: u32,
}

#[derive(Debug, Clone)]
pub struct SignalProcessor {
    pub id: String,
    pub name: String,
    pub processor_type: ProcessorType,
    pub parameters: HashMap<String, f64>,
    pub input_channels: Vec<u32>,
    pub output_channels: Vec<u32>,
}

#[derive(Debug, Clone)]
pub enum ProcessorType {
    Filter,
    FeatureExtractor,
    ArtifactRemover,
    Normalizer,
    Segmenter,
}

#[derive(Debug, Clone)]
pub struct NeuralDecoder {
    pub id: String,
    pub name: String,
    pub decoder_type: DecoderType,
    pub model: DecoderModel,
    pub training_data: Vec<TrainingSample>,
    pub performance_metrics: HashMap<String, f64>,
}

#[derive(Debug, Clone)]
pub enum DecoderType {
    Classification,
    Regression,
    Sequence,
    Continuous,
}

#[derive(Debug, Clone)]
pub struct DecoderModel {
    pub model_type: ModelType,
    pub parameters: HashMap<String, f64>,
    pub weights: Option<Array2<f64>>,
    pub biases: Option<Array1<f64>>,
    pub feature_names: Vec<String>,
}

#[derive(Debug, Clone)]
pub enum ModelType {
    LDA,
    SVM,
    RandomForest,
    NeuralNetwork,
    KalmanFilter,
    CSP,
    ICA,
}

#[derive(Debug, Clone)]
pub struct TrainingSample {
    pub features: Array1<f64>,
    pub label: Option<String>,
    pub target: Option<Array1<f64>>,
    pub timestamp: Instant,
    pub metadata: HashMap<String, String>,
}

#[derive(Debug, Clone)]
pub struct Controller {
    pub id: String,
    pub name: String,
    pub controller_type: ControllerType,
    pub output_mapping: HashMap<String, String>,
    pub parameters: HashMap<String, f64>,
}

#[derive(Debug, Clone)]
pub enum ControllerType {
    Cursor,
    Device,
    Communication,
    Gaming,
    Prosthetic,
}

#[derive(Debug, Clone)]
pub struct FeedbackSystem {
    pub id: String,
    pub name: String,
    pub feedback_type: FeedbackType,
    pub parameters: HashMap<String, f64>,
    pub channels: Vec<String>,
}

#[derive(Debug, Clone)]
pub enum FeedbackType {
    Visual,
    Auditory,
    Tactile,
    Haptic,
    Multimodal,
}

#[derive(Debug, Clone)]
pub struct BCIConfiguration {
    pub sampling_rate: u32,
    pub buffer_size: usize,
    pub processing_window: Duration,
    pub update_rate: Duration,
    pub enable_feedback: bool,
    pub enable_logging: bool,
    pub safety_limits: SafetyLimits,
}

#[derive(Debug, Clone)]
pub struct SafetyLimits {
    pub max_voltage: f32,
    pub max_current: f32,
    pub max_power: f32,
    pub temperature_limit: f32,
    pub impedance_threshold: f32,
}

#[derive(Debug, Clone)]
pub struct BCIState {
    pub current_signals: HashMap<String, SignalData>,
    pub processed_features: HashMap<String, FeatureVector>,
    pub decoder_outputs: HashMap<String, DecoderOutput>,
    pub controller_states: HashMap<String, ControllerState>,
    pub feedback_states: HashMap<String, FeedbackState>,
    pub system_health: SystemHealth,
    pub last_update: Instant,
}

#[derive(Debug, Clone)]
pub struct SignalData {
    pub channel_id: String,
    pub timestamp: Instant,
    pub raw_data: Vec<f64>,
    pub filtered_data: Vec<f64>,
    pub metadata: HashMap<String, String>,
}

#[derive(Debug, Clone)]
pub struct FeatureVector {
    pub feature_id: String,
    pub timestamp: Instant,
    pub features: Array1<f64>,
    pub feature_names: Vec<String>,
    pub quality_score: f64,
}

#[derive(Debug, Clone)]
pub struct DecoderOutput {
    pub decoder_id: String,
    pub timestamp: Instant,
    pub prediction: Option<String>,
    pub confidence: f64,
    pub continuous_output: Option<Array1<f64>>,
    pub probability_distribution: Option<HashMap<String, f64>>,
}

#[derive(Debug, Clone)]
pub struct ControllerState {
    pub controller_id: String,
    pub timestamp: Instant,
    pub output_values: HashMap<String, f64>,
    pub status: ControllerStatus,
}

#[derive(Debug, Clone)]
pub enum ControllerStatus {
    Active,
    Inactive,
    Error,
    Calibrating,
}

#[derive(Debug, Clone)]
pub struct FeedbackState {
    pub feedback_id: String,
    pub timestamp: Instant,
    pub feedback_values: HashMap<String, f64>,
    pub intensity: f64,
    pub duration: Duration,
}

#[derive(Debug, Clone)]
pub struct SystemHealth {
    pub overall_health: f64,
    pub signal_quality: f64,
    pub decoder_performance: f64,
    pub system_errors: Vec<SystemError>,
    pub warnings: Vec<Warning>,
}

#[derive(Debug, Clone)]
pub struct SystemError {
    pub error_id: String,
    pub error_type: String,
    pub message: String,
    pub timestamp: Instant,
    pub severity: ErrorSeverity,
}

#[derive(Debug, Clone)]
pub enum ErrorSeverity {
    Low,
    Medium,
    High,
    Critical,
}

#[derive(Debug, Clone)]
pub struct Warning {
    pub warning_id: String,
    pub warning_type: String,
    pub message: String,
    pub timestamp: Instant,
}

impl BCISystem {
    pub fn new(id: String, name: String, bci_type: BCIType, signal_type: SignalType) -> Self {
        BCISystem {
            id,
            name,
            bci_type,
            signal_type,
            electrodes: Vec::new(),
            amplifiers: Vec::new(),
            processors: Vec::new(),
            decoders: Vec::new(),
            controllers: Vec::new(),
            feedback_systems: Vec::new(),
            configuration: BCIConfiguration {
                sampling_rate: 1000,
                buffer_size: 1000,
                processing_window: Duration::from_millis(100),
                update_rate: Duration::from_millis(50),
                enable_feedback: true,
                enable_logging: true,
                safety_limits: SafetyLimits {
                    max_voltage: 5.0,
                    max_current: 0.001,
                    max_power: 0.005,
                    temperature_limit: 40.0,
                    impedance_threshold: 10000.0,
                },
            },
            state: Arc::new(Mutex::new(BCIState {
                current_signals: HashMap::new(),
                processed_features: HashMap::new(),
                decoder_outputs: HashMap::new(),
                controller_states: HashMap::new(),
                feedback_states: HashMap::new(),
                system_health: SystemHealth {
                    overall_health: 1.0,
                    signal_quality: 1.0,
                    decoder_performance: 1.0,
                    system_errors: Vec::new(),
                    warnings: Vec::new(),
                },
                last_update: Instant::now(),
            })),
        }
    }
    
    pub fn add_electrode(&mut self, electrode: Electrode) {
        self.electrodes.push(electrode);
    }
    
    pub fn add_amplifier(&mut self, amplifier: Amplifier) {
        self.amplifiers.push(amplifier);
    }
    
    pub fn add_processor(&mut self, processor: SignalProcessor) {
        self.processors.push(processor);
    }
    
    pub fn add_decoder(&mut self, decoder: NeuralDecoder) {
        self.decoders.push(decoder);
    }
    
    pub fn add_controller(&mut self, controller: Controller) {
        self.controllers.push(controller);
    }
    
    pub fn add_feedback_system(&mut self, feedback: FeedbackSystem) {
        self.feedback_systems.push(feedback);
    }
    
    pub async fn acquire_signals(&mut self) -> Result<Vec<SignalData>, String> {
        let mut signals = Vec::new();
        
        for electrode in &self.electrodes {
            if let Ok(signal_data) = self.read_electrode(electrode).await {
                signals.push(signal_data);
                
                // 更新状态
                let mut state = self.state.lock().unwrap();
                state.current_signals.insert(electrode.id.clone(), signal_data.clone());
            }
        }
        
        Ok(signals)
    }
    
    async fn read_electrode(&self, electrode: &Electrode) -> Result<SignalData, String> {
        // 模拟电极读取
        let mut raw_data = Vec::new();
        let mut filtered_data = Vec::new();
        
        for i in 0..100 {
            let sample = (i as f64 * 0.1).sin() * 50.0 + (rand::random::<f64>() - 0.5) * 10.0;
            raw_data.push(sample);
            filtered_data.push(sample * 0.9); // 简单滤波
        }
        
        let mut metadata = HashMap::new();
        metadata.insert("impedance".to_string(), electrode.impedance.to_string());
        metadata.insert("quality".to_string(), "good".to_string());
        
        Ok(SignalData {
            channel_id: electrode.id.clone(),
            timestamp: Instant::now(),
            raw_data,
            filtered_data,
            metadata,
        })
    }
    
    pub async fn process_signals(&mut self) -> Result<Vec<FeatureVector>, String> {
        let mut features = Vec::new();
        
        for processor in &self.processors {
            if let Ok(processor_features) = self.apply_processor(processor).await {
                features.extend(processor_features);
            }
        }
        
        // 更新状态
        let mut state = self.state.lock().unwrap();
        for feature in &features {
            state.processed_features.insert(feature.feature_id.clone(), feature.clone());
        }
        
        Ok(features)
    }
    
    async fn apply_processor(&self, processor: &SignalProcessor) -> Result<Vec<FeatureVector>, String> {
        match processor.processor_type {
            ProcessorType::FeatureExtractor => {
                // 简化的特征提取
                let features = vec![1.0, 2.0, 3.0, 4.0, 5.0];
                let feature_names = vec!["mean".to_string(), "variance".to_string(), "rms".to_string(), "peak".to_string(), "entropy".to_string()];
                
                Ok(vec![FeatureVector {
                    feature_id: processor.id.clone(),
                    timestamp: Instant::now(),
                    features: Array1::from_vec(features),
                    feature_names,
                    quality_score: 0.85,
                }])
            },
            _ => Ok(Vec::new()),
        }
    }
    
    pub async fn decode_signals(&mut self) -> Result<Vec<DecoderOutput>, String> {
        let mut outputs = Vec::new();
        
        for decoder in &self.decoders {
            if let Ok(decoder_output) = self.run_decoder(decoder).await {
                outputs.push(decoder_output.clone());
                
                // 更新状态
                let mut state = self.state.lock().unwrap();
                state.decoder_outputs.insert(decoder.id.clone(), decoder_output);
            }
        }
        
        Ok(outputs)
    }
    
    async fn run_decoder(&self, decoder: &NeuralDecoder) -> Result<DecoderOutput, String> {
        // 简化的解码器运行
        let prediction = Some("left".to_string());
        let confidence = 0.75;
        
        let mut probability_distribution = HashMap::new();
        probability_distribution.insert("left".to_string(), 0.75);
        probability_distribution.insert("right".to_string(), 0.15);
        probability_distribution.insert("center".to_string(), 0.10);
        
        Ok(DecoderOutput {
            decoder_id: decoder.id.clone(),
            timestamp: Instant::now(),
            prediction,
            confidence,
            continuous_output: None,
            probability_distribution: Some(probability_distribution),
        })
    }
    
    pub async fn control_devices(&mut self) -> Result<Vec<ControllerState>, String> {
        let mut controller_states = Vec::new();
        
        for controller in &self.controllers {
            if let Ok(controller_state) = self.execute_controller(controller).await {
                controller_states.push(controller_state.clone());
                
                // 更新状态
                let mut state = self.state.lock().unwrap();
                state.controller_states.insert(controller.id.clone(), controller_state);
            }
        }
        
        Ok(controller_states)
    }
    
    async fn execute_controller(&self, controller: &Controller) -> Result<ControllerState, String> {
        // 简化的控制器执行
        let mut output_values = HashMap::new();
        output_values.insert("x_position".to_string(), 100.0);
        output_values.insert("y_position".to_string(), 150.0);
        output_values.insert("click".to_string(), 0.0);
        
        Ok(ControllerState {
            controller_id: controller.id.clone(),
            timestamp: Instant::now(),
            output_values,
            status: ControllerStatus::Active,
        })
    }
    
    pub async fn provide_feedback(&mut self) -> Result<Vec<FeedbackState>, String> {
        let mut feedback_states = Vec::new();
        
        for feedback_system in &self.feedback_systems {
            if let Ok(feedback_state) = self.generate_feedback(feedback_system).await {
                feedback_states.push(feedback_state.clone());
                
                // 更新状态
                let mut state = self.state.lock().unwrap();
                state.feedback_states.insert(feedback_system.id.clone(), feedback_state);
            }
        }
        
        Ok(feedback_states)
    }
    
    async fn generate_feedback(&self, feedback_system: &FeedbackSystem) -> Result<FeedbackState, String> {
        // 简化的反馈生成
        let mut feedback_values = HashMap::new();
        feedback_values.insert("intensity".to_string(), 0.5);
        feedback_values.insert("frequency".to_string(), 100.0);
        
        Ok(FeedbackState {
            feedback_id: feedback_system.id.clone(),
            timestamp: Instant::now(),
            feedback_values,
            intensity: 0.5,
            duration: Duration::from_millis(100),
        })
    }
    
    pub fn get_system_health(&self) -> SystemHealth {
        let state = self.state.lock().unwrap();
        state.system_health.clone()
    }
    
    pub fn calibrate_decoder(&mut self, decoder_id: &str, training_data: Vec<TrainingSample>) -> Result<(), String> {
        if let Some(decoder) = self.decoders.iter_mut().find(|d| d.id == decoder_id) {
            decoder.training_data.extend(training_data);
            
            // 简化的校准过程
            let accuracy = 0.85;
            decoder.performance_metrics.insert("accuracy".to_string(), accuracy);
            
            // 更新系统健康状态
            let mut state = self.state.lock().unwrap();
            state.system_health.decoder_performance = accuracy;
        }
        
        Ok(())
    }
}

// 信号处理算法
pub struct SignalProcessor {
    pub id: String,
    pub name: String,
    pub algorithm: ProcessingAlgorithm,
    pub parameters: HashMap<String, f64>,
}

#[derive(Debug, Clone)]
pub enum ProcessingAlgorithm {
    BandpassFilter { low_freq: f64, high_freq: f64 },
    NotchFilter { notch_freq: f64, quality_factor: f64 },
    CSP { num_components: usize },
    ICA { num_components: usize },
    FeatureExtractor { feature_types: Vec<FeatureType> },
}

#[derive(Debug, Clone)]
pub enum FeatureType {
    TimeDomain,
    FrequencyDomain,
    TimeFrequency,
    Statistical,
}

impl SignalProcessor {
    pub fn new(id: String, name: String, algorithm: ProcessingAlgorithm) -> Self {
        SignalProcessor {
            id,
            name,
            algorithm,
            parameters: HashMap::new(),
        }
    }
    
    pub fn process_signal(&self, signal: &[f64]) -> Result<Vec<f64>, String> {
        match &self.algorithm {
            ProcessingAlgorithm::BandpassFilter { low_freq, high_freq } => {
                self.apply_bandpass_filter(signal, *low_freq, *high_freq)
            },
            ProcessingAlgorithm::NotchFilter { notch_freq, quality_factor } => {
                self.apply_notch_filter(signal, *notch_freq, *quality_factor)
            },
            ProcessingAlgorithm::CSP { num_components } => {
                self.apply_csp(signal, *num_components)
            },
            ProcessingAlgorithm::ICA { num_components } => {
                self.apply_ica(signal, *num_components)
            },
            ProcessingAlgorithm::FeatureExtractor { feature_types } => {
                self.extract_features(signal, feature_types)
            },
        }
    }
    
    fn apply_bandpass_filter(&self, signal: &[f64], low_freq: f64, high_freq: f64) -> Result<Vec<f64>, String> {
        // 简化的带通滤波器实现
        let filtered: Vec<f64> = signal.iter()
            .map(|&x| x * 0.9) // 简单的低通滤波
            .collect();
        
        Ok(filtered)
    }
    
    fn apply_notch_filter(&self, signal: &[f64], notch_freq: f64, quality_factor: f64) -> Result<Vec<f64>, String> {
        // 简化的陷波滤波器实现
        let filtered: Vec<f64> = signal.iter()
            .map(|&x| x * 0.95) // 简单的陷波滤波
            .collect();
        
        Ok(filtered)
    }
    
    fn apply_csp(&self, signal: &[f64], num_components: usize) -> Result<Vec<f64>, String> {
        // 简化的CSP实现
        let features: Vec<f64> = (0..num_components)
            .map(|i| signal.iter().sum::<f64>() / signal.len() as f64 + i as f64)
            .collect();
        
        Ok(features)
    }
    
    fn apply_ica(&self, signal: &[f64], num_components: usize) -> Result<Vec<f64>, String> {
        // 简化的ICA实现
        let components: Vec<f64> = (0..num_components)
            .map(|i| signal.iter().map(|&x| x * (i + 1) as f64).sum::<f64>() / signal.len() as f64)
            .collect();
        
        Ok(components)
    }
    
    fn extract_features(&self, signal: &[f64], feature_types: &[FeatureType]) -> Result<Vec<f64>, String> {
        let mut features = Vec::new();
        
        for feature_type in feature_types {
            match feature_type {
                FeatureType::TimeDomain => {
                    features.extend(self.extract_time_domain_features(signal));
                },
                FeatureType::FrequencyDomain => {
                    features.extend(self.extract_frequency_domain_features(signal));
                },
                FeatureType::TimeFrequency => {
                    features.extend(self.extract_time_frequency_features(signal));
                },
                FeatureType::Statistical => {
                    features.extend(self.extract_statistical_features(signal));
                },
            }
        }
        
        Ok(features)
    }
    
    fn extract_time_domain_features(&self, signal: &[f64]) -> Vec<f64> {
        let mean = signal.iter().sum::<f64>() / signal.len() as f64;
        let variance = signal.iter().map(|&x| (x - mean).powi(2)).sum::<f64>() / (signal.len() - 1) as f64;
        let rms = (signal.iter().map(|&x| x.powi(2)).sum::<f64>() / signal.len() as f64).sqrt();
        let peak_to_peak = signal.iter().max().unwrap() - signal.iter().min().unwrap();
        
        vec![mean, variance, rms, peak_to_peak]
    }
    
    fn extract_frequency_domain_features(&self, signal: &[f64]) -> Vec<f64> {
        // 简化的频域特征提取
        let fft_size = signal.len();
        let mut power_spectrum = vec![0.0; fft_size / 2];
        
        for i in 0..fft_size / 2 {
            power_spectrum[i] = signal.iter().map(|&x| x * (i as f64 * 0.1).cos()).sum::<f64>();
        }
        
        let total_power = power_spectrum.iter().sum::<f64>();
        let peak_frequency = power_spectrum.iter().enumerate().max_by(|a, b| a.1.partial_cmp(b.1).unwrap()).unwrap().0 as f64;
        
        vec![total_power, peak_frequency]
    }
    
    fn extract_time_frequency_features(&self, signal: &[f64]) -> Vec<f64> {
        // 简化的时频域特征提取
        let window_size = 64;
        let mut features = Vec::new();
        
        for i in 0..signal.len() - window_size {
            let window = &signal[i..i + window_size];
            let energy = window.iter().map(|&x| x.powi(2)).sum::<f64>();
            features.push(energy);
        }
        
        features
    }
    
    fn extract_statistical_features(&self, signal: &[f64]) -> Vec<f64> {
        let mean = signal.iter().sum::<f64>() / signal.len() as f64;
        let std = (signal.iter().map(|&x| (x - mean).powi(2)).sum::<f64>() / (signal.len() - 1) as f64).sqrt();
        let skewness = signal.iter().map(|&x| ((x - mean) / std).powi(3)).sum::<f64>() / signal.len() as f64;
        let kurtosis = signal.iter().map(|&x| ((x - mean) / std).powi(4)).sum::<f64>() / signal.len() as f64 - 3.0;
        
        vec![mean, std, skewness, kurtosis]
    }
}

// 机器学习解码器
pub struct MLDecoder {
    pub id: String,
    pub name: String,
    pub model_type: MLModelType,
    pub model: Box<dyn MLModel>,
    pub training_data: Vec<TrainingSample>,
    pub validation_data: Vec<TrainingSample>,
    pub performance_metrics: HashMap<String, f64>,
}

#[derive(Debug, Clone)]
pub enum MLModelType {
    LDA,
    SVM,
    RandomForest,
    NeuralNetwork,
    KalmanFilter,
}

pub trait MLModel: Send + Sync {
    fn train(&mut self, training_data: &[TrainingSample]) -> Result<(), String>;
    fn predict(&self, features: &Array1<f64>) -> Result<DecoderOutput, String>;
    fn evaluate(&self, test_data: &[TrainingSample]) -> Result<HashMap<String, f64>, String>;
}

pub struct LDAModel {
    pub weights: Option<Array1<f64>>,
    pub bias: Option<f64>>,
    pub classes: Vec<String>,
}

impl MLModel for LDAModel {
    fn train(&mut self, training_data: &[TrainingSample]) -> Result<(), String> {
        // 简化的LDA训练
        let num_features = training_data[0].features.len();
        self.weights = Some(Array1::zeros(num_features));
        self.bias = Some(0.0);
        
        // 收集类别
        let mut classes = std::collections::HashSet::new();
        for sample in training_data {
            if let Some(ref label) = sample.label {
                classes.insert(label.clone());
            }
        }
        self.classes = classes.into_iter().collect();
        
        Ok(())
    }
    
    fn predict(&self, features: &Array1<f64>) -> Result<DecoderOutput, String> {
        if let (Some(weights), Some(bias)) = (&self.weights, &self.bias) {
            let score = weights.dot(features) + bias;
            let prediction = if score > 0.0 { "class1" } else { "class2" };
            
            let mut probability_distribution = HashMap::new();
            probability_distribution.insert(prediction.to_string(), 0.8);
            probability_distribution.insert("other".to_string(), 0.2);
            
            Ok(DecoderOutput {
                decoder_id: "lda".to_string(),
                timestamp: Instant::now(),
                prediction: Some(prediction.to_string()),
                confidence: 0.8,
                continuous_output: None,
                probability_distribution: Some(probability_distribution),
            })
        } else {
            Err("Model not trained".to_string())
        }
    }
    
    fn evaluate(&self, test_data: &[TrainingSample]) -> Result<HashMap<String, f64>, String> {
        let mut correct = 0;
        let mut total = 0;
        
        for sample in test_data {
            if let Some(ref label) = sample.label {
                if let Ok(prediction) = self.predict(&sample.features) {
                    if let Some(ref pred_label) = prediction.prediction {
                        if pred_label == label {
                            correct += 1;
                        }
                    }
                }
                total += 1;
            }
        }
        
        let accuracy = correct as f64 / total as f64;
        let mut metrics = HashMap::new();
        metrics.insert("accuracy".to_string(), accuracy);
        
        Ok(metrics)
    }
}

pub struct NeuralNetworkModel {
    pub layers: Vec<Layer>,
    pub weights: Vec<Array2<f64>>,
    pub biases: Vec<Array1<f64>>,
    pub learning_rate: f64,
}

#[derive(Debug, Clone)]
pub struct Layer {
    pub input_size: usize,
    pub output_size: usize,
    pub activation: ActivationFunction,
}

#[derive(Debug, Clone)]
pub enum ActivationFunction {
    Sigmoid,
    ReLU,
    Tanh,
    Linear,
}

impl MLModel for NeuralNetworkModel {
    fn train(&mut self, training_data: &[TrainingSample]) -> Result<(), String> {
        // 简化的神经网络训练
        for _ in 0..100 { // 100 epochs
            for sample in training_data {
                // 前向传播
                let mut activations = vec![sample.features.clone()];
                
                for (layer_idx, layer) in self.layers.iter().enumerate() {
                    let input = &activations[layer_idx];
                    let output = self.forward_layer(input, layer, &self.weights[layer_idx], &self.biases[layer_idx]);
                    activations.push(output);
                }
                
                // 这里应该实现反向传播，但为了简化省略
            }
        }
        
        Ok(())
    }
    
    fn predict(&self, features: &Array1<f64>) -> Result<DecoderOutput, String> {
        // 前向传播
        let mut activations = vec![features.clone()];
        
        for (layer_idx, layer) in self.layers.iter().enumerate() {
            let input = &activations[layer_idx];
            let output = self.forward_layer(input, layer, &self.weights[layer_idx], &self.biases[layer_idx]);
            activations.push(output);
        }
        
        let output = &activations[activations.len() - 1];
        let prediction = if output[0] > 0.5 { "class1" } else { "class2" };
        
        let mut probability_distribution = HashMap::new();
        probability_distribution.insert(prediction.to_string(), output[0]);
        probability_distribution.insert("other".to_string(), 1.0 - output[0]);
        
        Ok(DecoderOutput {
            decoder_id: "neural_network".to_string(),
            timestamp: Instant::now(),
            prediction: Some(prediction.to_string()),
            confidence: output[0],
            continuous_output: None,
            probability_distribution: Some(probability_distribution),
        })
    }
    
    fn evaluate(&self, test_data: &[TrainingSample]) -> Result<HashMap<String, f64>, String> {
        let mut correct = 0;
        let mut total = 0;
        
        for sample in test_data {
            if let Some(ref label) = sample.label {
                if let Ok(prediction) = self.predict(&sample.features) {
                    if let Some(ref pred_label) = prediction.prediction {
                        if pred_label == label {
                            correct += 1;
                        }
                    }
                }
                total += 1;
            }
        }
        
        let accuracy = correct as f64 / total as f64;
        let mut metrics = HashMap::new();
        metrics.insert("accuracy".to_string(), accuracy);
        
        Ok(metrics)
    }
}

impl NeuralNetworkModel {
    fn forward_layer(&self, input: &Array1<f64>, layer: &Layer, weights: &Array2<f64>, bias: &Array1<f64>) -> Array1<f64> {
        let output = weights.dot(input) + bias;
        
        match layer.activation {
            ActivationFunction::Sigmoid => output.mapv(|x| 1.0 / (1.0 + (-x).exp())),
            ActivationFunction::ReLU => output.mapv(|x| x.max(0.0)),
            ActivationFunction::Tanh => output.mapv(|x| x.tanh()),
            ActivationFunction::Linear => output,
        }
    }
}
```

## 5. 批判性分析 / Critical Analysis

### 5.1 理论局限性 / Theoretical Limitations

- **信号质量限制 Signal Quality Limits**：非侵入式BCI信号质量有限。
- **个体差异 Individual Differences**：不同用户的脑信号模式差异。
- **疲劳效应 Fatigue Effects**：长时间使用导致的性能下降。

### 5.2 工程挑战 / Engineering Challenges

- **实时性要求 Real-time Requirements**：严格的实时处理要求。
- **安全性考虑 Safety Considerations**：侵入式BCI的安全风险。
- **用户体验 User Experience**：复杂系统的易用性挑战。

## 6. 工程论证 / Engineering Arguments

- **医疗康复**：如瘫痪患者的运动功能恢复，需高精度解码和实时控制。
- **辅助通信**：如渐冻症患者的通信辅助，需可靠的字符拼写系统。
- **神经科学研究**：如脑功能映射，需高时空分辨率的信号处理。

---
> 本文件为脑机接口基础的系统化重构，采用严格的形式化定义、数学表达、工程实现，确保内容的学术规范性和工程实用性。
> This file provides systematic refactoring of brain-computer interface fundamentals, using strict formal definitions, mathematical expressions, and engineering implementations, ensuring academic standards and engineering practicality.
