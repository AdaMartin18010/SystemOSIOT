# 5.2.1 实时系统 / Real-Time Systems


<!-- TOC START -->

- [5.2.1 实时系统 / Real-Time Systems](#521-实时系统-real-time-systems)
  - [5.2.1.1 实时系统基础 / Real-Time Systems Fundamentals](#5211-实时系统基础-real-time-systems-fundamentals)
    - [5.2.1.1.1 实时性分类 / Real-Time Classification](#52111-实时性分类-real-time-classification)
    - [5.2.1.1.2 时间分析理论 / Timing Analysis Theory](#52112-时间分析理论-timing-analysis-theory)
  - [5.2.1.2 实时调度算法 / Real-Time Scheduling Algorithms](#5212-实时调度算法-real-time-scheduling-algorithms)
    - [5.2.1.2.1 静态优先级调度 / Static Priority Scheduling](#52121-静态优先级调度-static-priority-scheduling)
    - [5.2.1.2.2 动态优先级调度 / Dynamic Priority Scheduling](#52122-动态优先级调度-dynamic-priority-scheduling)
    - [5.2.1.2.3 混合关键性调度 / Mixed-Criticality Scheduling](#52123-混合关键性调度-mixed-criticality-scheduling)
  - [5.2.1.3 资源管理与同步 / Resource Management and Synchronization](#5213-资源管理与同步-resource-management-and-synchronization)
    - [5.2.1.3.1 优先级继承协议 / Priority Inheritance Protocol](#52131-优先级继承协议-priority-inheritance-protocol)
  - [总结 / Summary](#总结-summary)

<!-- TOC END -->

## 5.2.1.1 实时系统基础 / Real-Time Systems Fundamentals

### 5.2.1.1.1 实时性分类 / Real-Time Classification

**实时系统类型定义：**

```text
实时系统分类 (Real-Time System Classification)
    ├── 硬实时系统 (Hard Real-Time Systems)
    │   ├── 绝对时间约束 (Absolute Timing Constraints)
    │   ├── 错过截止时间灾难性 (Missing Deadline is Catastrophic)
    │   ├── 应用场景：飞行控制、核反应堆控制、医疗设备
    │   └── 可预测性要求：100%
    │
    ├── 软实时系统 (Soft Real-Time Systems)
    │   ├── 相对时间约束 (Relative Timing Constraints)
    │   ├── 错过截止时间性能降级 (Missing Deadline Degrades Performance)
    │   ├── 应用场景：多媒体系统、网络通信、用户交互
    │   └── 可预测性要求：95-99%
    │
    ├── 坚实实时系统 (Firm Real-Time Systems)
    │   ├── 混合时间约束 (Mixed Timing Constraints)
    │   ├── 偶尔错过截止时间可接受 (Occasional Deadline Miss Acceptable)
    │   ├── 应用场景：传感器网络、数据采集、监控系统
    │   └── 可预测性要求：90-95%
    │
    └── 弱实时系统 (Weak Real-Time Systems)
        ├── 统计时间约束 (Statistical Timing Constraints)
        ├── 平均响应时间保证 (Average Response Time Guarantee)
        ├── 应用场景：Web服务、数据库、批处理
        └── 可预测性要求：80-90%
```

**实时任务模型：**

```rust
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use std::collections::{BinaryHeap, HashMap, VecDeque};
use std::cmp::Ordering;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum TaskType {
    Periodic,       // 周期任务
    Sporadic,       // 偶发任务
    Aperiodic,      // 非周期任务
    Interrupt,      // 中断任务
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum PriorityType {
    Static,         // 静态优先级
    Dynamic,        // 动态优先级
    Mixed,          // 混合优先级
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RealTimeTask {
    pub task_id: String,
    pub task_type: TaskType,
    pub priority: u32,
    pub priority_type: PriorityType,
    pub arrival_time: Duration,     // 到达时间
    pub computation_time: Duration, // 计算时间 (WCET)
    pub deadline: Duration,         // 相对截止时间
    pub period: Option<Duration>,   // 周期 (对周期任务)
    pub minimum_inter_arrival: Option<Duration>, // 最小到达间隔 (对偶发任务)
    pub resource_requirements: Vec<ResourceRequirement>,
    pub precedence_constraints: Vec<String>, // 前驱任务ID
    pub criticality_level: CriticalityLevel,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum CriticalityLevel {
    Critical = 4,   // 关键任务
    Important = 3,  // 重要任务
    Normal = 2,     // 普通任务
    Background = 1, // 后台任务
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResourceRequirement {
    pub resource_id: String,
    pub access_duration: Duration,
    pub access_type: ResourceAccessType,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ResourceAccessType {
    Exclusive,      // 独占访问
    Shared,         // 共享访问
    ReadOnly,       // 只读访问
    WriteOnly,      // 只写访问
}

#[derive(Debug, Clone)]
pub struct TaskInstance {
    pub task: RealTimeTask,
    pub instance_id: u64,
    pub absolute_arrival_time: SystemTime,
    pub absolute_deadline: SystemTime,
    pub start_time: Option<SystemTime>,
    pub finish_time: Option<SystemTime>,
    pub remaining_time: Duration,
    pub is_completed: bool,
    pub missed_deadline: bool,
    pub preempted_count: u32,
}

impl TaskInstance {
    pub fn new(task: RealTimeTask, instance_id: u64, arrival_time: SystemTime) -> Self {
        let absolute_deadline = arrival_time + task.deadline;
        
        Self {
            remaining_time: task.computation_time,
            task,
            instance_id,
            absolute_arrival_time: arrival_time,
            absolute_deadline,
            start_time: None,
            finish_time: None,
            is_completed: false,
            missed_deadline: false,
            preempted_count: 0,
        }
    }
    
    pub fn execute(&mut self, execution_time: Duration) -> bool {
        if self.remaining_time <= execution_time {
            // 任务完成
            self.remaining_time = Duration::from_nanos(0);
            self.finish_time = Some(SystemTime::now());
            self.is_completed = true;
            true
        } else {
            // 任务被抢占或时间片用完
            self.remaining_time -= execution_time;
            self.preempted_count += 1;
            false
        }
    }
    
    pub fn is_deadline_missed(&self) -> bool {
        SystemTime::now() > self.absolute_deadline && !self.is_completed
    }
    
    pub fn response_time(&self) -> Option<Duration> {
        if let (Some(finish), start) = (self.finish_time, self.absolute_arrival_time) {
            finish.duration_since(start).ok()
        } else {
            None
        }
    }
}

// 为优先级队列实现排序
impl Ord for TaskInstance {
    fn cmp(&self, other: &Self) -> Ordering {
        // 最早截止时间优先 (EDF)
        other.absolute_deadline.cmp(&self.absolute_deadline)
    }
}

impl PartialOrd for TaskInstance {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl PartialEq for TaskInstance {
    fn eq(&self, other: &Self) -> bool {
        self.instance_id == other.instance_id
    }
}

impl Eq for TaskInstance {}

#[derive(Debug)]
pub struct RealTimeSystem {
    tasks: HashMap<String, RealTimeTask>,
    ready_queue: BinaryHeap<TaskInstance>,
    running_task: Option<TaskInstance>,
    completed_tasks: VecDeque<TaskInstance>,
    current_time: SystemTime,
    scheduler: Box<dyn RealTimeScheduler + Send + Sync>,
    resource_manager: ResourceManager,
    timing_analyzer: TimingAnalyzer,
}

pub trait RealTimeScheduler: Send + Sync {
    fn schedule(&mut self, ready_queue: &mut BinaryHeap<TaskInstance>, current_time: SystemTime) -> Option<TaskInstance>;
    fn preempt_decision(&self, current_task: &TaskInstance, new_task: &TaskInstance) -> bool;
    fn get_scheduler_name(&self) -> &'static str;
}
```

### 5.2.1.1.2 时间分析理论 / Timing Analysis Theory

**最坏情况执行时间(WCET)分析：**

```rust
use std::collections::HashMap;

#[derive(Debug, Clone)]
pub struct ControlFlowGraph {
    pub nodes: Vec<CFGNode>,
    pub edges: Vec<CFGEdge>,
    pub entry_node: usize,
    pub exit_nodes: Vec<usize>,
}

#[derive(Debug, Clone)]
pub struct CFGNode {
    pub node_id: usize,
    pub basic_block: BasicBlock,
    pub worst_case_cycles: u64,
    pub best_case_cycles: u64,
}

#[derive(Debug, Clone)]
pub struct BasicBlock {
    pub instructions: Vec<Instruction>,
    pub cache_behavior: CacheBehavior,
    pub pipeline_effects: PipelineEffects,
}

#[derive(Debug, Clone)]
pub struct Instruction {
    pub opcode: String,
    pub operands: Vec<String>,
    pub base_cycles: u32,
    pub cache_penalty: u32,
    pub pipeline_stalls: u32,
}

#[derive(Debug, Clone)]
pub struct CFGEdge {
    pub from_node: usize,
    pub to_node: usize,
    pub condition: Option<String>,
    pub execution_count: Option<u64>, // 循环边界信息
}

#[derive(Debug, Clone)]
pub enum CacheBehavior {
    AlwaysHit,      // 始终命中
    AlwaysMiss,     // 始终缺失
    FirstMiss,      // 首次缺失
    Unknown,        // 未知
}

#[derive(Debug, Clone)]
pub struct PipelineEffects {
    pub data_hazards: u32,
    pub control_hazards: u32,
    pub structural_hazards: u32,
}

#[derive(Debug)]
pub struct WCETAnalyzer {
    cfg: ControlFlowGraph,
    cache_analyzer: CacheAnalyzer,
    pipeline_analyzer: PipelineAnalyzer,
    loop_bounds: HashMap<usize, LoopBound>, // node_id -> bound
}

#[derive(Debug, Clone)]
pub struct LoopBound {
    pub min_iterations: u64,
    pub max_iterations: u64,
    pub typical_iterations: u64,
}

impl WCETAnalyzer {
    pub fn new(cfg: ControlFlowGraph) -> Self {
        Self {
            cfg,
            cache_analyzer: CacheAnalyzer::new(),
            pipeline_analyzer: PipelineAnalyzer::new(),
            loop_bounds: HashMap::new(),
        }
    }
    
    pub fn analyze_wcet(&mut self) -> Result<WCETResult, &'static str> {
        // 1. 低级分析：指令级时间
        self.analyze_instruction_timing()?;
        
        // 2. 中级分析：基本块级时间
        self.analyze_basic_block_timing()?;
        
        // 3. 高级分析：程序级时间
        let wcet = self.analyze_program_timing()?;
        
        Ok(WCETResult {
            worst_case_cycles: wcet,
            worst_case_time: Duration::from_nanos(wcet * 1000 / 100), // 假设100MHz
            analysis_confidence: self.calculate_confidence(),
            critical_path: self.find_critical_path(),
            cache_effects: self.cache_analyzer.get_summary(),
            pipeline_effects: self.pipeline_analyzer.get_summary(),
        })
    }
    
    fn analyze_instruction_timing(&mut self) -> Result<(), &'static str> {
        for node in &mut self.cfg.nodes {
            let mut node_cycles = 0u64;
            
            for instruction in &mut node.basic_block.instructions {
                // 基础执行时间
                let mut instr_cycles = instruction.base_cycles as u64;
                
                // 缓存效应
                let cache_penalty = self.cache_analyzer.analyze_instruction_cache(instruction);
                instr_cycles += cache_penalty;
                
                // 流水线效应
                let pipeline_penalty = self.pipeline_analyzer.analyze_pipeline_effects(instruction);
                instr_cycles += pipeline_penalty;
                
                node_cycles += instr_cycles;
            }
            
            node.worst_case_cycles = node_cycles;
        }
        
        Ok(())
    }
    
    fn analyze_basic_block_timing(&mut self) -> Result<(), &'static str> {
        // 分析基本块间的缓存效应
        for edge in &self.cfg.edges {
            let from_node = &self.cfg.nodes[edge.from_node];
            let to_node = &self.cfg.nodes[edge.to_node];
            
            // 分析控制流转移的缓存影响
            let transition_penalty = self.cache_analyzer.analyze_control_flow_transition(from_node, to_node);
            
            // 将惩罚添加到目标节点
            // 这里简化处理，实际需要更复杂的分析
        }
        
        Ok(())
    }
    
    fn analyze_program_timing(&self) -> Result<u64, &'static str> {
        // 使用隐式路径枚举技术 (IPET) 计算WCET
        self.ipet_analysis()
    }
    
    fn ipet_analysis(&self) -> Result<u64, &'static str> {
        // 构建整数线性规划 (ILP) 问题
        let mut objective_function = 0u64;
        
        // 简化的IPET分析
        // 实际实现需要使用ILP求解器
        
        // 1. 结构约束：每个节点的执行次数
        let mut node_execution_counts = HashMap::new();
        node_execution_counts.insert(self.cfg.entry_node, 1u64);
        
        // 2. 循环约束：循环边界
        for (node_id, loop_bound) in &self.loop_bounds {
            let max_executions = node_execution_counts.get(node_id).unwrap_or(&0) * loop_bound.max_iterations;
            node_execution_counts.insert(*node_id, max_executions);
        }
        
        // 3. 计算目标函数
        for (node_id, executions) in &node_execution_counts {
            if let Some(node) = self.cfg.nodes.get(*node_id) {
                objective_function += node.worst_case_cycles * executions;
            }
        }
        
        Ok(objective_function)
    }
    
    fn find_critical_path(&self) -> Vec<usize> {
        // 查找最长路径 (关键路径)
        let mut path = Vec::new();
        let mut current = self.cfg.entry_node;
        path.push(current);
        
        // 简化的贪心算法
        while !self.cfg.exit_nodes.contains(&current) {
            let mut best_next = None;
            let mut best_cycles = 0;
            
            for edge in &self.cfg.edges {
                if edge.from_node == current {
                    let to_node = &self.cfg.nodes[edge.to_node];
                    if to_node.worst_case_cycles > best_cycles {
                        best_cycles = to_node.worst_case_cycles;
                        best_next = Some(edge.to_node);
                    }
                }
            }
            
            if let Some(next) = best_next {
                current = next;
                path.push(current);
            } else {
                break;
            }
        }
        
        path
    }
    
    fn calculate_confidence(&self) -> f64 {
        // 计算分析的置信度
        let mut confidence = 1.0;
        
        // 根据未知的缓存行为降低置信度
        for node in &self.cfg.nodes {
            if matches!(node.basic_block.cache_behavior, CacheBehavior::Unknown) {
                confidence *= 0.8;
            }
        }
        
        // 根据循环边界的确定性降低置信度
        if self.loop_bounds.is_empty() {
            confidence *= 0.7;
        }
        
        confidence
    }
    
    pub fn add_loop_bound(&mut self, node_id: usize, bound: LoopBound) {
        self.loop_bounds.insert(node_id, bound);
    }
}

#[derive(Debug, Clone)]
pub struct WCETResult {
    pub worst_case_cycles: u64,
    pub worst_case_time: Duration,
    pub analysis_confidence: f64,
    pub critical_path: Vec<usize>,
    pub cache_effects: CacheAnalysisSummary,
    pub pipeline_effects: PipelineAnalysisSummary,
}

// 缓存分析器
#[derive(Debug)]
pub struct CacheAnalyzer {
    instruction_cache_size: usize,
    data_cache_size: usize,
    cache_line_size: usize,
    associativity: usize,
}

impl CacheAnalyzer {
    pub fn new() -> Self {
        Self {
            instruction_cache_size: 16384,  // 16KB
            data_cache_size: 16384,         // 16KB
            cache_line_size: 32,            // 32 bytes
            associativity: 4,               // 4-way set associative
        }
    }
    
    pub fn analyze_instruction_cache(&self, instruction: &Instruction) -> u64 {
        // 简化的指令缓存分析
        match instruction.opcode.as_str() {
            "JUMP" | "CALL" | "RET" => 10, // 控制流指令可能导致缓存缺失
            "LOAD" | "STORE" => 5,         // 内存访问指令
            _ => 0,                        // 其他指令通常在缓存中
        }
    }
    
    pub fn analyze_control_flow_transition(&self, _from: &CFGNode, _to: &CFGNode) -> u64 {
        // 分析控制流转移的缓存惩罚
        2 // 简化为固定惩罚
    }
    
    pub fn get_summary(&self) -> CacheAnalysisSummary {
        CacheAnalysisSummary {
            instruction_cache_misses: 0,
            data_cache_misses: 0,
            cache_miss_penalty: 10,
        }
    }
}

#[derive(Debug, Clone)]
pub struct CacheAnalysisSummary {
    pub instruction_cache_misses: u32,
    pub data_cache_misses: u32,
    pub cache_miss_penalty: u32,
}

// 流水线分析器
#[derive(Debug)]
pub struct PipelineAnalyzer {
    pipeline_depth: usize,
    forwarding_enabled: bool,
    branch_predictor: bool,
}

impl PipelineAnalyzer {
    pub fn new() -> Self {
        Self {
            pipeline_depth: 5,         // 5级流水线
            forwarding_enabled: true,
            branch_predictor: true,
        }
    }
    
    pub fn analyze_pipeline_effects(&self, instruction: &Instruction) -> u64 {
        let mut penalty = 0;
        
        // 数据冒险
        if instruction.operands.len() > 1 && !self.forwarding_enabled {
            penalty += 1; // RAW hazard
        }
        
        // 控制冒险
        if matches!(instruction.opcode.as_str(), "JUMP" | "CALL" | "RET") {
            if self.branch_predictor {
                penalty += 1; // 分支预测错误惩罚
            } else {
                penalty += self.pipeline_depth as u64 - 1; // 流水线刷新
            }
        }
        
        // 结构冒险
        if matches!(instruction.opcode.as_str(), "MUL" | "DIV") {
            penalty += 2; // 功能单元冲突
        }
        
        penalty
    }
    
    pub fn get_summary(&self) -> PipelineAnalysisSummary {
        PipelineAnalysisSummary {
            data_hazard_stalls: 0,
            control_hazard_stalls: 0,
            structural_hazard_stalls: 0,
        }
    }
}

#[derive(Debug, Clone)]
pub struct PipelineAnalysisSummary {
    pub data_hazard_stalls: u32,
    pub control_hazard_stalls: u32,
    pub structural_hazard_stalls: u32,
}

// 时间分析器
#[derive(Debug)]
pub struct TimingAnalyzer {
    wcet_cache: HashMap<String, WCETResult>,
    response_time_cache: HashMap<String, Duration>,
}

impl TimingAnalyzer {
    pub fn new() -> Self {
        Self {
            wcet_cache: HashMap::new(),
            response_time_cache: HashMap::new(),
        }
    }
    
    pub fn analyze_task_set_schedulability(&self, tasks: &[RealTimeTask]) -> SchedulabilityResult {
        let mut result = SchedulabilityResult {
            is_schedulable: true,
            utilization: 0.0,
            response_times: HashMap::new(),
            deadline_miss_probability: HashMap::new(),
        };
        
        // 计算CPU利用率
        let mut total_utilization = 0.0;
        
        for task in tasks {
            if let Some(period) = task.period {
                let utilization = task.computation_time.as_secs_f64() / period.as_secs_f64();
                total_utilization += utilization;
                
                // 使用响应时间分析 (RTA)
                let response_time = self.calculate_response_time(task, tasks);
                result.response_times.insert(task.task_id.clone(), response_time);
                
                // 检查截止时间约束
                if response_time > task.deadline {
                    result.is_schedulable = false;
                }
            }
        }
        
        result.utilization = total_utilization;
        
        // 应用调度理论测试
        if total_utilization > 1.0 {
            result.is_schedulable = false;
        }
        
        result
    }
    
    fn calculate_response_time(&self, task: &RealTimeTask, task_set: &[RealTimeTask]) -> Duration {
        // 使用响应时间分析计算最坏情况响应时间
        let mut response_time = task.computation_time;
        let mut prev_response_time = Duration::from_secs(0);
        
        // 迭代计算直到收敛
        while response_time != prev_response_time {
            prev_response_time = response_time;
            let mut interference = Duration::from_secs(0);
            
            // 计算高优先级任务的干扰
            for other_task in task_set {
                if other_task.priority > task.priority {
                    if let Some(period) = other_task.period {
                        let preemptions = (response_time.as_secs_f64() / period.as_secs_f64()).ceil() as u64;
                        interference += other_task.computation_time * preemptions as u32;
                    }
                }
            }
            
            response_time = task.computation_time + interference;
            
            // 防止无限循环
            if response_time > Duration::from_secs(3600) {
                break;
            }
        }
        
        response_time
    }
}

#[derive(Debug, Clone)]
pub struct SchedulabilityResult {
    pub is_schedulable: bool,
    pub utilization: f64,
    pub response_times: HashMap<String, Duration>,
    pub deadline_miss_probability: HashMap<String, f64>,
}
```

## 5.2.1.2 实时调度算法 / Real-Time Scheduling Algorithms

### 5.2.1.2.1 静态优先级调度 / Static Priority Scheduling

**Rate Monotonic (RM) 调度器实现：**

```rust
use std::cmp::Ordering;

#[derive(Debug)]
pub struct RateMonotonicScheduler {
    priority_assignments: HashMap<String, u32>,
}

impl RateMonotonicScheduler {
    pub fn new() -> Self {
        Self {
            priority_assignments: HashMap::new(),
        }
    }
    
    pub fn assign_priorities(&mut self, tasks: &[RealTimeTask]) {
        // Rate Monotonic: 周期越短，优先级越高
        let mut sorted_tasks: Vec<_> = tasks.iter().collect();
        sorted_tasks.sort_by(|a, b| {
            match (a.period, b.period) {
                (Some(period_a), Some(period_b)) => period_a.cmp(&period_b),
                (Some(_), None) => Ordering::Less,    // 周期任务优先级高于非周期任务
                (None, Some(_)) => Ordering::Greater,
                (None, None) => a.task_id.cmp(&b.task_id), // 按ID排序
            }
        });
        
        for (index, task) in sorted_tasks.iter().enumerate() {
            // 优先级值越大，优先级越高
            let priority = (sorted_tasks.len() - index) as u32 * 10;
            self.priority_assignments.insert(task.task_id.clone(), priority);
        }
    }
    
    pub fn schedulability_test(&self, tasks: &[RealTimeTask]) -> bool {
        // Liu & Layland 充分条件测试
        let n = tasks.len() as f64;
        let bound = n * (2.0_f64.powf(1.0 / n) - 1.0);
        
        let mut total_utilization = 0.0;
        for task in tasks {
            if let Some(period) = task.period {
                total_utilization += task.computation_time.as_secs_f64() / period.as_secs_f64();
            }
        }
        
        total_utilization <= bound
    }
}

impl RealTimeScheduler for RateMonotonicScheduler {
    fn schedule(&mut self, ready_queue: &mut BinaryHeap<TaskInstance>, _current_time: SystemTime) -> Option<TaskInstance> {
        // 选择优先级最高的任务
        let mut highest_priority_task = None;
        let mut highest_priority = 0;
        
        let tasks: Vec<_> = ready_queue.drain().collect();
        
        for task in tasks {
            let priority = self.priority_assignments.get(&task.task.task_id).unwrap_or(&0);
            if *priority > highest_priority {
                if let Some(prev_task) = highest_priority_task {
                    ready_queue.push(prev_task);
                }
                highest_priority = *priority;
                highest_priority_task = Some(task);
            } else {
                ready_queue.push(task);
            }
        }
        
        highest_priority_task
    }
    
    fn preempt_decision(&self, current_task: &TaskInstance, new_task: &TaskInstance) -> bool {
        let current_priority = self.priority_assignments.get(&current_task.task.task_id).unwrap_or(&0);
        let new_priority = self.priority_assignments.get(&new_task.task.task_id).unwrap_or(&0);
        
        new_priority > current_priority
    }
    
    fn get_scheduler_name(&self) -> &'static str {
        "Rate Monotonic"
    }
}

// Deadline Monotonic (DM) 调度器
#[derive(Debug)]
pub struct DeadlineMonotonicScheduler {
    priority_assignments: HashMap<String, u32>,
}

impl DeadlineMonotonicScheduler {
    pub fn new() -> Self {
        Self {
            priority_assignments: HashMap::new(),
        }
    }
    
    pub fn assign_priorities(&mut self, tasks: &[RealTimeTask]) {
        // Deadline Monotonic: 截止时间越短，优先级越高
        let mut sorted_tasks: Vec<_> = tasks.iter().collect();
        sorted_tasks.sort_by(|a, b| a.deadline.cmp(&b.deadline));
        
        for (index, task) in sorted_tasks.iter().enumerate() {
            let priority = (sorted_tasks.len() - index) as u32 * 10;
            self.priority_assignments.insert(task.task_id.clone(), priority);
        }
    }
}

impl RealTimeScheduler for DeadlineMonotonicScheduler {
    fn schedule(&mut self, ready_queue: &mut BinaryHeap<TaskInstance>, _current_time: SystemTime) -> Option<TaskInstance> {
        let mut highest_priority_task = None;
        let mut highest_priority = 0;
        
        let tasks: Vec<_> = ready_queue.drain().collect();
        
        for task in tasks {
            let priority = self.priority_assignments.get(&task.task.task_id).unwrap_or(&0);
            if *priority > highest_priority {
                if let Some(prev_task) = highest_priority_task {
                    ready_queue.push(prev_task);
                }
                highest_priority = *priority;
                highest_priority_task = Some(task);
            } else {
                ready_queue.push(task);
            }
        }
        
        highest_priority_task
    }
    
    fn preempt_decision(&self, current_task: &TaskInstance, new_task: &TaskInstance) -> bool {
        let current_priority = self.priority_assignments.get(&current_task.task.task_id).unwrap_or(&0);
        let new_priority = self.priority_assignments.get(&new_task.task.task_id).unwrap_or(&0);
        
        new_priority > current_priority
    }
    
    fn get_scheduler_name(&self) -> &'static str {
        "Deadline Monotonic"
    }
}
```

### 5.2.1.2.2 动态优先级调度 / Dynamic Priority Scheduling

**Earliest Deadline First (EDF) 调度器实现：**

```rust
#[derive(Debug)]
pub struct EarliestDeadlineFirstScheduler {
    preemptive: bool,
}

impl EarliestDeadlineFirstScheduler {
    pub fn new(preemptive: bool) -> Self {
        Self { preemptive }
    }
    
    pub fn schedulability_test(&self, tasks: &[RealTimeTask]) -> bool {
        // EDF的最优性：利用率测试
        let mut total_utilization = 0.0;
        
        for task in tasks {
            if let Some(period) = task.period {
                total_utilization += task.computation_time.as_secs_f64() / period.as_secs_f64();
            }
        }
        
        total_utilization <= 1.0
    }
}

impl RealTimeScheduler for EarliestDeadlineFirstScheduler {
    fn schedule(&mut self, ready_queue: &mut BinaryHeap<TaskInstance>, _current_time: SystemTime) -> Option<TaskInstance> {
        // BinaryHeap已经按截止时间排序 (通过TaskInstance的Ord实现)
        ready_queue.pop()
    }
    
    fn preempt_decision(&self, current_task: &TaskInstance, new_task: &TaskInstance) -> bool {
        self.preemptive && new_task.absolute_deadline < current_task.absolute_deadline
    }
    
    fn get_scheduler_name(&self) -> &'static str {
        if self.preemptive {
            "Preemptive EDF"
        } else {
            "Non-preemptive EDF"
        }
    }
}

// Least Laxity First (LLF) 调度器
#[derive(Debug)]
pub struct LeastLaxityFirstScheduler;

impl LeastLaxityFirstScheduler {
    pub fn new() -> Self {
        Self
    }
    
    fn calculate_laxity(&self, task: &TaskInstance, current_time: SystemTime) -> i64 {
        let remaining_time_to_deadline = task.absolute_deadline
            .duration_since(current_time)
            .unwrap_or(Duration::from_secs(0))
            .as_millis() as i64;
        
        let remaining_computation = task.remaining_time.as_millis() as i64;
        
        remaining_time_to_deadline - remaining_computation
    }
}

impl RealTimeScheduler for LeastLaxityFirstScheduler {
    fn schedule(&mut self, ready_queue: &mut BinaryHeap<TaskInstance>, current_time: SystemTime) -> Option<TaskInstance> {
        let tasks: Vec<_> = ready_queue.drain().collect();
        
        if tasks.is_empty() {
            return None;
        }
        
        // 计算每个任务的松弛度并选择最小的
        let mut min_laxity = i64::MAX;
        let mut selected_task = None;
        let mut remaining_tasks = Vec::new();
        
        for task in tasks {
            let laxity = self.calculate_laxity(&task, current_time);
            
            if laxity < min_laxity {
                if let Some(prev_task) = selected_task {
                    remaining_tasks.push(prev_task);
                }
                min_laxity = laxity;
                selected_task = Some(task);
            } else {
                remaining_tasks.push(task);
            }
        }
        
        // 将未选中的任务放回队列
        for task in remaining_tasks {
            ready_queue.push(task);
        }
        
        selected_task
    }
    
    fn preempt_decision(&self, current_task: &TaskInstance, new_task: &TaskInstance) -> bool {
        let current_time = SystemTime::now();
        let current_laxity = self.calculate_laxity(current_task, current_time);
        let new_laxity = self.calculate_laxity(new_task, current_time);
        
        new_laxity < current_laxity
    }
    
    fn get_scheduler_name(&self) -> &'static str {
        "Least Laxity First"
    }
}
```

### 5.2.1.2.3 混合关键性调度 / Mixed-Criticality Scheduling

**混合关键性系统调度器：**

```rust
#[derive(Debug, Clone)]
pub enum SystemMode {
    LowCriticality,     // 低关键性模式
    HighCriticality,    // 高关键性模式
}

#[derive(Debug)]
pub struct MixedCriticalityScheduler {
    current_mode: SystemMode,
    rm_scheduler: RateMonotonicScheduler,
    edf_scheduler: EarliestDeadlineFirstScheduler,
    mode_change_protocol: ModeChangeProtocol,
    budget_enforcement: BudgetEnforcement,
}

#[derive(Debug)]
pub struct ModeChangeProtocol {
    mode_change_threshold: Duration,    // 模式切换阈值
    stabilization_time: Duration,       // 稳定时间
    last_mode_change: Option<SystemTime>,
}

#[derive(Debug)]
pub struct BudgetEnforcement {
    task_budgets: HashMap<String, Duration>,      // 任务预算
    consumed_budgets: HashMap<String, Duration>,  // 已消耗预算
    budget_reset_time: SystemTime,                // 预算重置时间
}

impl MixedCriticalityScheduler {
    pub fn new() -> Self {
        Self {
            current_mode: SystemMode::LowCriticality,
            rm_scheduler: RateMonotonicScheduler::new(),
            edf_scheduler: EarliestDeadlineFirstScheduler::new(true),
            mode_change_protocol: ModeChangeProtocol {
                mode_change_threshold: Duration::from_millis(100),
                stabilization_time: Duration::from_secs(1),
                last_mode_change: None,
            },
            budget_enforcement: BudgetEnforcement {
                task_budgets: HashMap::new(),
                consumed_budgets: HashMap::new(),
                budget_reset_time: SystemTime::now(),
            },
        }
    }
    
    pub fn set_task_budget(&mut self, task_id: String, budget: Duration) {
        self.budget_enforcement.task_budgets.insert(task_id, budget);
    }
    
    fn check_mode_change_condition(&mut self, ready_queue: &BinaryHeap<TaskInstance>, current_time: SystemTime) -> bool {
        // 检查是否需要切换到高关键性模式
        match self.current_mode {
            SystemMode::LowCriticality => {
                // 检查低关键性任务是否超出预算
                for task in ready_queue.iter() {
                    if let CriticalityLevel::Critical = task.task.criticality_level {
                        continue; // 跳过高关键性任务
                    }
                    
                    if let Some(budget) = self.budget_enforcement.task_budgets.get(&task.task.task_id) {
                        let consumed = self.budget_enforcement.consumed_budgets.get(&task.task.task_id).unwrap_or(&Duration::from_secs(0));
                        if *consumed > *budget {
                            return true; // 需要切换到高关键性模式
                        }
                    }
                    
                    // 检查截止时间约束
                    if task.is_deadline_missed() {
                        return true;
                    }
                }
                false
            }
            SystemMode::HighCriticality => {
                // 检查是否可以切换回低关键性模式
                if let Some(last_change) = self.mode_change_protocol.last_mode_change {
                    if current_time.duration_since(last_change).unwrap_or(Duration::from_secs(0)) 
                        >= self.mode_change_protocol.stabilization_time {
                        // 检查系统是否稳定
                        return self.system_is_stable(ready_queue);
                    }
                }
                false
            }
        }
    }
    
    fn system_is_stable(&self, ready_queue: &BinaryHeap<TaskInstance>) -> bool {
        // 检查系统是否稳定，可以切换回低关键性模式
        for task in ready_queue.iter() {
            if let CriticalityLevel::Critical = task.task.criticality_level {
                if task.is_deadline_missed() {
                    return false;
                }
            }
        }
        true
    }
    
    fn handle_mode_change(&mut self, new_mode: SystemMode, current_time: SystemTime) {
        match new_mode {
            SystemMode::HighCriticality => {
                println!("Switching to High-Criticality mode");
                // 丢弃所有低关键性任务
                self.drop_low_criticality_tasks();
            }
            SystemMode::LowCriticality => {
                println!("Switching to Low-Criticality mode");
                // 重新启用低关键性任务
                self.restore_low_criticality_tasks();
            }
        }
        
        self.current_mode = new_mode;
        self.mode_change_protocol.last_mode_change = Some(current_time);
    }
    
    fn drop_low_criticality_tasks(&mut self) {
        // 在实际实现中，这里会从就绪队列中移除低关键性任务
        println!("Dropping low-criticality tasks");
    }
    
    fn restore_low_criticality_tasks(&mut self) {
        // 在实际实现中，这里会重新添加低关键性任务到就绪队列
        println!("Restoring low-criticality tasks");
    }
    
    fn filter_tasks_by_mode(&self, ready_queue: &mut BinaryHeap<TaskInstance>) {
        match self.current_mode {
            SystemMode::LowCriticality => {
                // 在低关键性模式下，所有任务都可以执行
            }
            SystemMode::HighCriticality => {
                // 在高关键性模式下，只有高关键性任务可以执行
                let tasks: Vec<_> = ready_queue.drain().collect();
                for task in tasks {
                    if matches!(task.task.criticality_level, CriticalityLevel::Critical | CriticalityLevel::Important) {
                        ready_queue.push(task);
                    }
                    // 丢弃低关键性任务
                }
            }
        }
    }
    
    fn update_budget_consumption(&mut self, task_id: &str, execution_time: Duration) {
        let consumed = self.budget_enforcement.consumed_budgets.entry(task_id.to_string()).or_insert(Duration::from_secs(0));
        *consumed += execution_time;
    }
    
    fn reset_budgets_if_needed(&mut self, current_time: SystemTime) {
        // 检查是否需要重置预算 (例如，每个周期开始时)
        if current_time.duration_since(self.budget_enforcement.budget_reset_time).unwrap_or(Duration::from_secs(0)) 
            >= Duration::from_secs(1) { // 1秒重置一次
            self.budget_enforcement.consumed_budgets.clear();
            self.budget_enforcement.budget_reset_time = current_time;
        }
    }
}

impl RealTimeScheduler for MixedCriticalityScheduler {
    fn schedule(&mut self, ready_queue: &mut BinaryHeap<TaskInstance>, current_time: SystemTime) -> Option<TaskInstance> {
        // 重置预算
        self.reset_budgets_if_needed(current_time);
        
        // 检查模式切换条件
        if self.check_mode_change_condition(ready_queue, current_time) {
            let new_mode = match self.current_mode {
                SystemMode::LowCriticality => SystemMode::HighCriticality,
                SystemMode::HighCriticality => SystemMode::LowCriticality,
            };
            self.handle_mode_change(new_mode, current_time);
        }
        
        // 根据当前模式过滤任务
        self.filter_tasks_by_mode(ready_queue);
        
        // 根据模式选择调度算法
        match self.current_mode {
            SystemMode::LowCriticality => {
                // 在低关键性模式下使用RM调度
                self.rm_scheduler.schedule(ready_queue, current_time)
            }
            SystemMode::HighCriticality => {
                // 在高关键性模式下使用EDF调度
                self.edf_scheduler.schedule(ready_queue, current_time)
            }
        }
    }
    
    fn preempt_decision(&self, current_task: &TaskInstance, new_task: &TaskInstance) -> bool {
        // 高关键性任务总是可以抢占低关键性任务
        if matches!(new_task.task.criticality_level, CriticalityLevel::Critical) &&
           !matches!(current_task.task.criticality_level, CriticalityLevel::Critical) {
            return true;
        }
        
        // 在相同关键性级别内，使用当前模式的调度策略
        match self.current_mode {
            SystemMode::LowCriticality => {
                self.rm_scheduler.preempt_decision(current_task, new_task)
            }
            SystemMode::HighCriticality => {
                self.edf_scheduler.preempt_decision(current_task, new_task)
            }
        }
    }
    
    fn get_scheduler_name(&self) -> &'static str {
        match self.current_mode {
            SystemMode::LowCriticality => "Mixed-Criticality (Low Mode)",
            SystemMode::HighCriticality => "Mixed-Criticality (High Mode)",
        }
    }
}
```

## 5.2.1.3 资源管理与同步 / Resource Management and Synchronization

### 5.2.1.3.1 优先级继承协议 / Priority Inheritance Protocol

**优先级继承和优先级天花板协议：**

```rust
use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use tokio::sync::Mutex;

#[derive(Debug, Clone)]
pub struct SharedResource {
    pub resource_id: String,
    pub resource_type: ResourceType,
    pub max_concurrent_users: u32,
    pub current_users: u32,
    pub ceiling_priority: u32,      // 优先级天花板
    pub owner: Option<String>,      // 当前拥有者任务ID
    pub waiting_queue: VecDeque<String>, // 等待队列
}

#[derive(Debug, Clone)]
pub enum ResourceType {
    Mutex,          // 互斥锁
    Semaphore,      // 信号量
    MessageQueue,   // 消息队列
    SharedMemory,   // 共享内存
    NetworkSocket,  // 网络套接字
}

#[derive(Debug)]
pub struct ResourceManager {
    resources: HashMap<String, SharedResource>,
    task_priorities: HashMap<String, u32>,      // 任务原始优先级
    inherited_priorities: HashMap<String, u32>, // 继承的优先级
    resource_access_graph: AccessGraph,
    deadlock_detector: DeadlockDetector,
}

#[derive(Debug)]
pub struct AccessGraph {
    nodes: HashSet<String>,                     // 任务节点
    edges: HashMap<String, HashSet<String>>,   // 等待关系边
}

#[derive(Debug)]
pub struct DeadlockDetector {
    wait_for_graph: HashMap<String, HashSet<String>>,
    detection_enabled: bool,
}

impl ResourceManager {
    pub fn new() -> Self {
        Self {
            resources: HashMap::new(),
            task_priorities: HashMap::new(),
            inherited_priorities: HashMap::new(),
            resource_access_graph: AccessGraph::new(),
            deadlock_detector: DeadlockDetector::new(),
        }
    }
    
    pub fn register_resource(&mut self, resource: SharedResource) {
        self.resources.insert(resource.resource_id.clone(), resource);
    }
    
    pub fn register_task(&mut self, task_id: String, priority: u32) {
        self.task_priorities.insert(task_id.clone(), priority);
        self.inherited_priorities.insert(task_id, priority);
    }
    
    // 基本优先级继承协议 (Basic Priority Inheritance Protocol)
    pub async fn request_resource_pip(&mut self, task_id: &str, resource_id: &str) -> Result<(), ResourceError> {
        let task_priority = self.get_effective_priority(task_id);
        
        if let Some(resource) = self.resources.get_mut(resource_id) {
            if resource.current_users < resource.max_concurrent_users {
                // 资源可用，直接分配
                resource.current_users += 1;
                resource.owner = Some(task_id.to_string());
                
                self.resource_access_graph.add_resource_access(task_id, resource_id);
                Ok(())
            } else {
                // 资源被占用，需要等待
                resource.waiting_queue.push_back(task_id.to_string());
                
                // 优先级继承
                if let Some(owner) = &resource.owner {
                    self.inherit_priority(owner, task_priority)?;
                }
                
                self.resource_access_graph.add_wait_edge(task_id, resource.owner.as_ref().unwrap());
                
                // 检查死锁
                if self.deadlock_detector.detect_deadlock(task_id) {
                    return Err(ResourceError::DeadlockDetected);
                }
                
                Err(ResourceError::ResourceBusy)
            }
        } else {
            Err(ResourceError::ResourceNotFound)
        }
    }
    
    pub async fn release_resource_pip(&mut self, task_id: &str, resource_id: &str) -> Result<(), ResourceError> {
        if let Some(resource) = self.resources.get_mut(resource_id) {
            if resource.owner.as_ref() == Some(&task_id.to_string()) {
                resource.current_users -= 1;
                resource.owner = None;
                
                // 恢复原始优先级
                self.restore_priority(task_id);
                
                // 将资源分配给等待队列中优先级最高的任务
                if !resource.waiting_queue.is_empty() {
                    let next_task = self.select_highest_priority_waiter(&resource.waiting_queue)?;
                    resource.waiting_queue.retain(|t| t != &next_task);
                    resource.owner = Some(next_task.clone());
                    resource.current_users += 1;
                    
                    self.resource_access_graph.remove_wait_edge(&next_task, task_id);
                    self.resource_access_graph.add_resource_access(&next_task, resource_id);
                }
                
                self.resource_access_graph.remove_resource_access(task_id, resource_id);
                Ok(())
            } else {
                Err(ResourceError::NotOwner)
            }
        } else {
            Err(ResourceError::ResourceNotFound)
        }
    }
    
    // 优先级天花板协议 (Priority Ceiling Protocol)
    pub async fn request_resource_pcp(&mut self, task_id: &str, resource_id: &str) -> Result<(), ResourceError> {
        let task_priority = self.get_effective_priority(task_id);
        
        if let Some(resource) = self.resources.get_mut(resource_id) {
            // 检查是否违反优先级天花板
            if task_priority <= resource.ceiling_priority {
                return Err(ResourceError::CeilingViolation);
            }
            
            // 检查是否有其他任务占用了优先级天花板更高的资源
            for (_, other_resource) in &self.resources {
                if other_resource.resource_id != resource_id && 
                   other_resource.current_users > 0 && 
                   other_resource.ceiling_priority > task_priority {
                    return Err(ResourceError::CeilingBlocked);
                }
            }
            
            if resource.current_users == 0 {
                // 资源可用
                resource.current_users += 1;
                resource.owner = Some(task_id.to_string());
                
                // 提升任务优先级到天花板优先级
                self.set_priority(task_id, resource.ceiling_priority);
                
                Ok(())
            } else {
                Err(ResourceError::ResourceBusy)
            }
        } else {
            Err(ResourceError::ResourceNotFound)
        }
    }
    
    pub async fn release_resource_pcp(&mut self, task_id: &str, resource_id: &str) -> Result<(), ResourceError> {
        if let Some(resource) = self.resources.get_mut(resource_id) {
            if resource.owner.as_ref() == Some(&task_id.to_string()) {
                resource.current_users = 0;
                resource.owner = None;
                
                // 恢复任务的原始优先级
                self.restore_priority(task_id);
                
                Ok(())
            } else {
                Err(ResourceError::NotOwner)
            }
        } else {
            Err(ResourceError::ResourceNotFound)
        }
    }
    
    // 栈资源策略 (Stack Resource Policy)
    pub async fn request_resource_srp(&mut self, task_id: &str, resource_id: &str) -> Result<(), ResourceError> {
        let task_priority = self.get_effective_priority(task_id);
        
        if let Some(resource) = self.resources.get_mut(resource_id) {
            // 检查当前系统天花板
            let system_ceiling = self.calculate_system_ceiling();
            
            if task_priority <= system_ceiling {
                // 任务被系统天花板阻塞
                return Err(ResourceError::SystemCeilingBlocked);
            }
            
            if resource.current_users == 0 {
                resource.current_users += 1;
                resource.owner = Some(task_id.to_string());
                Ok(())
            } else {
                Err(ResourceError::ResourceBusy)
            }
        } else {
            Err(ResourceError::ResourceNotFound)
        }
    }
    
    fn inherit_priority(&mut self, task_id: &str, new_priority: u32) -> Result<(), ResourceError> {
        if let Some(current_priority) = self.inherited_priorities.get_mut(task_id) {
            if new_priority > *current_priority {
                *current_priority = new_priority;
                
                // 传递继承：如果该任务正在等待其他资源，继续传播优先级
                self.propagate_inheritance(task_id, new_priority)?;
            }
        }
        Ok(())
    }
    
    fn propagate_inheritance(&mut self, task_id: &str, priority: u32) -> Result<(), ResourceError> {
        // 查找该任务正在等待的资源
        for (_, resource) in &mut self.resources {
            if resource.waiting_queue.contains(&task_id.to_string()) {
                if let Some(owner) = &resource.owner {
                    self.inherit_priority(owner, priority)?;
                }
            }
        }
        Ok(())
    }
    
    fn restore_priority(&mut self, task_id: &str) {
        if let Some(original_priority) = self.task_priorities.get(task_id) {
            self.inherited_priorities.insert(task_id.to_string(), *original_priority);
        }
    }
    
    fn set_priority(&mut self, task_id: &str, priority: u32) {
        self.inherited_priorities.insert(task_id.to_string(), priority);
    }
    
    fn get_effective_priority(&self, task_id: &str) -> u32 {
        self.inherited_priorities.get(task_id).copied().unwrap_or(0)
    }
    
    fn select_highest_priority_waiter(&self, waiting_queue: &VecDeque<String>) -> Result<String, ResourceError> {
        let mut highest_priority = 0;
        let mut selected_task = None;
        
        for task_id in waiting_queue {
            let priority = self.get_effective_priority(task_id);
            if priority > highest_priority {
                highest_priority = priority;
                selected_task = Some(task_id.clone());
            }
        }
        
        selected_task.ok_or(ResourceError::NoWaitingTasks)
    }
    
    fn calculate_system_ceiling(&self) -> u32 {
        let mut max_ceiling = 0;
        
        for (_, resource) in &self.resources {
            if resource.current_users > 0 && resource.ceiling_priority > max_ceiling {
                max_ceiling = resource.ceiling_priority;
            }
        }
        
        max_ceiling
    }
    
    pub fn calculate_blocking_time(&self, task_id: &str) -> Duration {
        let task_priority = self.get_effective_priority(task_id);
        let mut max_blocking = Duration::from_secs(0);
        
        // 计算来自低优先级任务的最大阻塞时间
        for (_, resource) in &self.resources {
            if resource.ceiling_priority >= task_priority {
                // 该资源可能阻塞当前任务
                let critical_section_time = Duration::from_millis(10); // 简化假设
                if critical_section_time > max_blocking {
                    max_blocking = critical_section_time;
                }
            }
        }
        
        max_blocking
    }
}

impl AccessGraph {
    pub fn new() -> Self {
        Self {
            nodes: HashSet::new(),
            edges: HashMap::new(),
        }
    }
    
    pub fn add_resource_access(&mut self, task_id: &str, _resource_id: &str) {
        self.nodes.insert(task_id.to_string());
    }
    
    pub fn remove_resource_access(&mut self, task_id: &str, _resource_id: &str) {
        // 简化实现
        self.nodes.remove(task_id);
    }
    
    pub fn add_wait_edge(&mut self, waiter: &str, owner: &str) {
        self.edges.entry(waiter.to_string())
            .or_insert_with(HashSet::new)
            .insert(owner.to_string());
    }
    
    pub fn remove_wait_edge(&mut self, waiter: &str, owner: &str) {
        if let Some(edges) = self.edges.get_mut(waiter) {
            edges.remove(owner);
            if edges.is_empty() {
                self.edges.remove(waiter);
            }
        }
    }
}

impl DeadlockDetector {
    pub fn new() -> Self {
        Self {
            wait_for_graph: HashMap::new(),
            detection_enabled: true,
        }
    }
    
    pub fn detect_deadlock(&self, task_id: &str) -> bool {
        if !self.detection_enabled {
            return false;
        }
        
        // 使用DFS检测环路
        let mut visited = HashSet::new();
        let mut rec_stack = HashSet::new();
        
        self.has_cycle_dfs(task_id, &mut visited, &mut rec_stack)
    }
    
    fn has_cycle_dfs(&self, node: &str, visited: &mut HashSet<String>, rec_stack: &mut HashSet<String>) -> bool {
        visited.insert(node.to_string());
        rec_stack.insert(node.to_string());
        
        if let Some(neighbors) = self.wait_for_graph.get(node) {
            for neighbor in neighbors {
                if !visited.contains(neighbor) {
                    if self.has_cycle_dfs(neighbor, visited, rec_stack) {
                        return true;
                    }
                } else if rec_stack.contains(neighbor) {
                    return true; // 找到环路
                }
            }
        }
        
        rec_stack.remove(node);
        false
    }
}

#[derive(Debug)]
pub enum ResourceError {
    ResourceNotFound,
    ResourceBusy,
    NotOwner,
    DeadlockDetected,
    CeilingViolation,
    CeilingBlocked,
    SystemCeilingBlocked,
    NoWaitingTasks,
}

// 使用示例和测试
pub fn demonstrate_priority_inheritance() {
    println!("=== Priority Inheritance Protocol Demo ===");
    
    let mut resource_manager = ResourceManager::new();
    
    // 注册任务
    resource_manager.register_task("T1".to_string(), 10); // 高优先级
    resource_manager.register_task("T2".to_string(), 5);  // 中优先级
    resource_manager.register_task("T3".to_string(), 1);  // 低优先级
    
    // 注册资源
    let resource = SharedResource {
        resource_id: "R1".to_string(),
        resource_type: ResourceType::Mutex,
        max_concurrent_users: 1,
        current_users: 0,
        ceiling_priority: 15, // 高于所有任务的优先级
        owner: None,
        waiting_queue: VecDeque::new(),
    };
    resource_manager.register_resource(resource);
    
    println!("Initial priorities: T1=10, T2=5, T3=1");
    
    // 模拟优先级倒置场景
    println!("\n1. T3 (low priority) acquires resource R1");
    // 在实际系统中这里会是异步调用
    
    println!("2. T1 (high priority) requests resource R1 - blocked!");
    // T1被阻塞，T3继承T1的优先级
    
    println!("3. T3 inherits priority from T1: 1 -> 10");
    
    println!("4. T2 (medium priority) becomes ready - cannot preempt T3!");
    // T3现在有高优先级，T2无法抢占
    
    println!("5. T3 completes and releases R1");
    // T3恢复原始优先级，T1获得资源
    
    println!("6. T1 gets resource R1 and continues execution");
    
    println!("\nPriority inheritance successfully prevents priority inversion!");
}
```

## 总结 / Summary

本文档全面介绍了实时系统的核心概念和技术，包括：

1. **实时系统基础**：实时性分类、任务模型和时间分析理论
2. **实时调度算法**：静态优先级调度(RM/DM)、动态优先级调度(EDF/LLF)和混合关键性调度
3. **资源管理与同步**：优先级继承协议、优先级天花板协议和死锁检测

实时系统的设计需要在时间约束、资源利用率和系统复杂性之间进行权衡。通过合适的调度算法和资源管理策略，可以确保系统满足时间约束要求，同时保持良好的性能和可预测性。关键是要根据应用的实时性要求选择合适的技术组合。
